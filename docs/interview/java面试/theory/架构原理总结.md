## 分布式原理

**1：分布式锁**

数据库的唯一索引、Redis 的 SETNX 指令、Redis 的 RedLock 算法、Zookeeper 的有序节点

**2：分布式事务**

2PC、本地消息表、seata

**3：分布式理论**

CAP、BASE、Paxos、Raft 

## zookeeper 原理

> 简单的说，zookeeper=文件系统+通知机制。Zookeeper维护一个类似文件系统的数据结构。每个子目录项如 NameService 都被称作为 znode，和文件系统一样，我们能够自由的增加、删除 znode，唯一的不同在于znode是可以存储数据的。有四种类型的znode，PERSISTENT-持久化目录节点、PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点、EPHEMERAL-临时目录节点、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点。客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。

**我们能用zookeeper做什么**

**1、 命名服务**

​    这个似乎最简单，在zookeeper的文件系统里创建一个目录，即有唯一的path。

**2、 配置管理**

​    程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。

​                     ![zookeeper简介](http://static.open-open.com/lib/uploadImg/20141108/20141108213345_625.png)

 

**3、 集群管理**

所谓集群管理无在乎两点：是否有机器退出和加入、选举master。

​    对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。

​    对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。

​                 ![zookeeper简介](http://static.open-open.com/lib/uploadImg/20141108/20141108213345_947.png)

 

**4、 分布式锁**

​    有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。

​    对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。厕所有言：来也冲冲，去也冲冲，用完删除掉自己创建的distribute_lock 节点就释放出锁。

​    对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。

​                     ![zookeeper简介](http://static.open-open.com/lib/uploadImg/20141108/20141108213345_5.png)

**5、 队列管理**

两种类型的队列：

1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。

2、队列按照 FIFO 方式进行入队和出队操作。

第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。

第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。         

**ZooKeeper的工作原理**

​    Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。

​    为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上 了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。

每个Server在工作过程中有三种状态：

- LOOKING：当前Server不知道leader是谁，正在搜寻
- LEADING：当前Server即为选举出来的leader
- FOLLOWING：leader已经选举出来，当前Server与之同步

## dubbo 原理

**dubbo**是一个分布式服务中间件，是高性能和透明化的RPC远程服务调用解决方案，主要通过资源调度和服务治理来解决分布式架构下服务资源浪费以提高集群的使用率。核心部分包含：

- 远程通讯：提供多种基于长连接的NIO的抽象封装，包括多种线程模型，序列化方式，以及请求-响应模式的信息交互
- 集群容错：提供基于接口方法的透明化远程调用，包括多协议支持，软负载均衡，失败容错，地址路由，动态配置的集群策略
- 服务发现：基于注册中心目录服务，使服务消费者能动态查找服务提供者，使地址透明，服务提供者可以根据流量平滑增加节点

在深入架构前，先了解一下dubbo的组件角色，如下图： 

- Provider：暴露服务的服务提供方
- Container：服务运行容器
- Registry：服务注册与发现的注册中心
- Consumer：调用远程服务的服务消费方
- Monitor：统计服务调用次数和耗时的监控中心

调用关系分析：

- 服务容器Container负责启动，加载，运行服务提供者。
- 服务提供者Provider在启动时，向注册中心注册自己提供的服务。
- 服务消费者Consumer在启动时，向注册中心订阅自己所需的服务。
- 注册中心Registry返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
- 服务消费者Consumer，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
- 服务消费者Consumer和提供者Provider，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心Monitor。

Dubbo 和 Spring Cloud 有什么区别？

```undefined
1、通信方式不同：Dubbo 使用的是 RPC 通信，而Spring Cloud 使用的是HTTP RESTFul 方式。
2、组成不一样：
dubbo的服务注册中心为Zookeerper，服务监控中心为dubbo-monitor,无消息总线，服务跟踪、批量任务等组件；
spring-cloud的服务注册中心为spring-cloud netflix  enruka，服务监控中心为spring-boot admin,有消息总线，数据流、服务跟踪、批量任务等组件；
```

**dubbo协议**

​     1.采用单一长链接和NIO异步通讯，适合小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。

​     2.Dubbo协议底层默认使用的是netty，性能非常优秀，官方推荐使用此协议。

​     3.不适合传输大数据量的服务，如传输文件，传视频等，除非请求量很低。

​     4.<dubbo:protocol  name="dubbo"  port="20880" />，使用此标签来设置其他协议，默认端口为20880。

**hessian协议**

​     Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现。

## kafka 原理

Kafka是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由LinkedIn公司开发，使用Scala语言编写，目前是Apache的开源项目。

跟RabbitMQ、RocketMQ等目前流行的开源消息中间件相比，Kakfa具有高吞吐、低延迟等特点，在大数据、日志收集等应用场景下被广泛使用。

基本概念：

- broker：Kafka服务器，负责消息存储和转发
- topic：消息类别，Kafka按照topic来分类消息
- partition：topic的分区，一个topic可以包含多个partition，topic消息保存在各个partition上
- offset：消息在日志中的位置，可以理解是消息在partition上的偏移量，也是代表该消息的唯一序号
- Producer：消息生产者
- Consumer：消息消费者
- Consumer Group：消费者分组，每个Consumer必须属于一个group
- Zookeeper：保存着集群broker、topic、partition等meta数据；另外，还负责broker故障发现，partition leader选举，负载均衡等功能

3.1 数据存储设计

3.2 生产者设计

3.3 消费者设计

3.4 Replication设计

3.5 高吞吐设计

3.6  HA 基本原理



## rabbitMq 原理

**为什么使用消息队列**

消息队列用于系统之间解耦，通过高性能消息中间件，提升系统吞吐量，降低导致系统耦合。 当前有各种消息队列，RabbitMQ、Kafka、ActiveMQ等，为什么使用RabbitMQ？ 消息队列从使用场景来分为两类：

- 一类是大数据的数据流处理，数据采集者作为生产者数据通过消息队列从到后端处理。这种场景要求高吞吐高并发，Kafka专门为这种场景设计。
- 另一类是消息高可靠低时延在系统之间传递，这种场景要求可靠性高，消息不能丢；要求时延低。AMQP协议专门为这种场景设计，RabbitMQ是AMQP协议实现者之一，也是当前使用的最广的AMQP消息队列。

**RabbitMQ 基本概念**

上面只是最简单抽象的描述，具体到 RabbitMQ 则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念：

![img](https:////upload-images.jianshu.io/upload_images/5015984-367dd717d89ae5db.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp)

​																				RabbitMQ 内部结构

1. Message
   消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。
2. Publisher
   消息的生产者，也是一个向交换器发布消息的客户端应用程序。
3. Exchange
   交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。
4. Binding
   绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。
5. Queue
   消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。
6. Connection
   网络连接，比如一个TCP连接。
7. Channel
   信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。
8. Consumer
   消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。
9. Virtual Host
   虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。
10. Broker
     表示消息队列服务器实体。

我们先来了解下RabbitMQ中的相关概念，这里以5种消息模式中的`路由模式`为例。

![img](http://www.macrozheng.com/images/rabbitmq_start_01.png)

| 标志   | 中文名        | 英文名   | 描述                                             |
| ------ | ------------- | -------- | ------------------------------------------------ |
| P      | 生产者        | Producer | 消息的发送者，可以将消息发送到交换机             |
| C      | 消费者        | Consumer | 消息的接收者，从队列中获取消息并进行消费         |
| X      | 交换机        | Exchange | 接收生产者发送的消息，并根据路由键发送给指定队列 |
| Q      | 队列          | Queue    | 存储从交换机发来的消息                           |
| type   | 交换机类型    | type     | 不同类型的交换机转发消息方式不同                 |
| fanout | 发布/订阅模式 | fanout   | 广播消息给所有绑定交换机的队列                   |
| direct | 路由模式      | direct   | 根据路由键发送消息                               |
| topic  | 通配符模式    | topic    | 根据路由键的匹配规则发送消息                     |

**5种消息模式**

> 这5种消息模式是构建基于RabbitMQ的消息应用的基础，一定要牢牢掌握它们。学过RabbitMQ的朋友应该了解过这些消息模式的Java实现，这里我们使用Spring AMQP的形式来实现它们。

**简单模式**

> 简单模式是最简单的消息模式，它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。

![img](http://www.macrozheng.com/images/rabbitmq_start_12.png)

**工作模式**

> 工作模式是指向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。

![img](http://www.macrozheng.com/images/rabbitmq_start_15.png)

**发布/订阅模式**

> 发布/订阅模式是指同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。

![img](http://www.macrozheng.com/images/rabbitmq_start_19.png)

**路由模式**

> 路由模式是可以根据`路由键`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过`路由键`绑定到交换机上去，生产者发送消息到交换机，交换机通过`路由键`转发到不同队列，队列绑定的消费者接收并消费消息。

![img](http://www.macrozheng.com/images/rabbitmq_start_23.png)

**通配符模式**

> 通配符模式是可以根据`路由键匹配规则`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过`路由键匹配规则`绑定到交换机上去，生产者发送消息到交换机，交换机通过`路由键匹配规则`转发到不同队列，队列绑定的消费者接收并消费消息。

**特殊匹配符号**

- `*`：只能匹配一个单词；
- `#`：可以匹配零个或多个单词。

![img](http://www.macrozheng.com/images/rabbitmq_start_27.png)

**死信队列DLX**

**`死信队列(DLX Dead-Letter-Exchange)：`**利用DLX，当消息在一个队列中变成死信(dead message)之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。

DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。

当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列。

可以监听这个队列中消息做相应的处理，这个特性可以弥补RabbitMQ3.0之前支持的immediate参数的功能。

**消息变成死信的几种情况：**

- 消息被拒绝(basic.reject/basic.nack)并且requeue=false
- 消息TTL过期
- 队列达到最大长度

**死信队列设置：**需要设置死信队列的exchange和queue，然后通过routing key进行绑定。**只不过我们需要在队列加上一个参数即可**。



## 消息队列

#### 1：消息可靠性

丢数据一般分为两种，一种是mq把消息丢了，一种就是消费时将消息丢了。下面从rabbitmq和kafka分别说一下，丢失数据的场景，
 （1）rabbitmq
 **A:生产者弄丢了数据**
 生产者将数据发送到rabbitmq的时候，可能在传输过程中因为网络等问题而将数据弄丢了。
 **B:rabbitmq自己丢了数据**
 如果没有开启rabbitmq的持久化，那么rabbitmq一旦重启，那么数据就丢了。所依必须开启持久化将消息持久化到磁盘，这样就算rabbitmq挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢失。除非极其罕见的情况，rabbitmq还没来得及持久化自己就挂了，这样可能导致一部分数据丢失。
 **C：消费端弄丢了数据**
 主要是因为消费者消费时，刚消费到，还没有处理，结果消费者就挂了，这样你重启之后，rabbitmq就认为你已经消费过了，然后就丢了数据。

![img](https:////upload-images.jianshu.io/upload_images/8494967-a279a2bf41cfc412.png?imageMogr2/auto-orient/strip|imageView2/2/w/1052/format/webp)


 （2）kafka
**A:生产者弄丢了数据**
 生产者没有设置相应的策略，发送过程中丢失数据。
**B:kafka弄丢了数据**
 比较常见的一个场景，就是kafka的某个broker宕机了，然后重新选举partition的leader时。如果此时follower还没来得及同步数据，leader就挂了，然后某个follower成为了leader，他就少了一部分数据。
**C:消费者弄丢了数据**
 消费者消费到了这个数据，然后消费之自动提交了offset，让kafka知道你已经消费了这个消息，当你准备处理这个消息时，自己挂掉了，那么这条消息就丢了。



![img](https:////upload-images.jianshu.io/upload_images/8494967-1c745e1dbb3b9143.png?imageMogr2/auto-orient/strip|imageView2/2/w/816/format/webp)



**3.如何防止消息丢失**

（1）rabbitmq
 **A:生产者丢失消息**
 ①：可以选择使用rabbitmq提供是事物功能，就是生产者在发送数据之前开启事物，然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会受到异常报错，这时就可以回滚事物，然后尝试重新发送；如果收到了消息，那么就可以提交事物。



```cpp
  channel.txSelect();//开启事物
  try{
      //发送消息
  }catch(Exection e){
      channel.txRollback()；//回滚事物
      //重新提交
  }
```

**缺点：**rabbitmq事物已开启，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。

②：可以开启confirm模式。在生产者哪里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如何写入了rabbitmq之中，rabbitmq会给你回传一个ack消息，告诉你这个消息发送OK了；如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息失败了，你可以进行重试。而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么你可以进行重发。



```cpp
    //开启confirm
    channel.confirm();
    //发送成功回调
    public void ack(String messageId){
      
    }

    // 发送失败回调
    public void nack(String messageId){
        //重发该消息
    }
```

**二者不同**
 事务机制是同步的，你提交了一个事物之后会阻塞住，但是confirm机制是异步的，发送消息之后可以接着发送下一个消息，然后rabbitmq会回调告知成功与否。
 一般在生产者这块避免丢失，都是用confirm机制。
 **B:rabbitmq自己弄丢了数据**
 设置消息持久化到磁盘。设置持久化有两个步骤：
 ①创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里面的数据。
 ②发送消息的时候讲消息的deliveryMode设置为2，这样消息就会被设为持久化方式，此时rabbitmq就会将消息持久化到磁盘上。
 必须要同时开启这两个才可以。

而且持久化可以跟生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前rabbitmq挂了，数据丢了，生产者收不到ack回调也会进行消息重发。
 **C:消费者弄丢了数据**
 使用rabbitmq提供的ack机制，首先关闭rabbitmq的自动ack，然后每次在确保处理完这个消息之后，在代码里手动调用ack。这样就可以避免消息还没有处理完就ack。

（2）kafka
 **A:消费端弄丢了数据**
 关闭自动提交offset，在自己处理完毕之后手动提交offset，这样就不会丢失数据。
 **B:kafka弄丢了数据**
 一般要求设置4个参数来保证消息不丢失：
 ①给topic设置 **replication.factor**参数：这个值必须大于1，表示要求每个partition必须至少有2个副本。

②在kafka服务端设置**min.isync.replicas**参数：这个值必须大于1，表示 要求一个leader至少感知到有至少一个follower在跟自己保持联系正常同步数据，这样才能保证leader挂了之后还有一个follower。

③在生产者端设置**acks=all**：表示 要求每条每条数据，必须是写入所有replica副本之后，才能认为是写入成功了

④在生产者端设置**retries=MAX**(很大的一个值，表示无限重试)：表示 这个是要求一旦写入事变，就无限重试
 **C：生产者弄丢了数据**
 如果按照上面设置了ack=all，则一定不会丢失数据，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。



#### 2：消息重复消费

要保证消息的幂等性，这个要结合业务的类型来进行处理。下面提供几个思路供参考：

1. 可在内存中维护一个set，只要从消息队列里面获取到一个消息，先查询这个消息在不在set里面，如果在表示已消费过，直接丢弃；如果不在，则在消费后将其加入set当中。
2. 如何要写数据库，可以拿唯一键先去数据库查询一下，如果不存在在写，如果存在直接更新或者丢弃消息。
   如果是写redis那没有问题，每次都是set，天然的幂等性。
3. 让生产者发送消息时，每条消息加一个全局的唯一id，然后消费时，将该id保存到redis里面。消费时先去redis里面查一下有么有，没有再消费。
4. 数据库操作可以设置唯一键，防止重复数据的插入，这样插入只会报错而不会插入重复数据。

#### 3：消息顺序执行

**3.1 出现顺序错乱的场景**

（1）rabbitmq
 ①一个queue，有多个consumer去消费，这样就会造成顺序的错误，consumer从MQ里面读取数据是有序的，但是每个consumer的执行时间是不固定的，无法保证先读到消息的consumer一定先完成操作，这样就会出现消息并没有按照顺序执行，造成数据顺序错误。



![img](https:////upload-images.jianshu.io/upload_images/8494967-e450c6cb00e84866.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②一个queue对应一个consumer，但是consumer里面进行了多线程消费，这样也会造成消息消费顺序错误。



![img](https:////upload-images.jianshu.io/upload_images/8494967-65a77852d22d0833.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

（2）kafka
 ①kafka一个topic，一个partition，一个consumer，但是consumer内部进行多线程消费，这样数据也会出现顺序错乱问题。



![img](https:////upload-images.jianshu.io/upload_images/8494967-8cc85c5a6cc9bbf5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②具有顺序的数据写入到了不同的partition里面，不同的消费者去消费，但是每个consumer的执行时间是不固定的，无法保证先读到消息的consumer一定先完成操作，这样就会出现消息并没有按照顺序执行，造成数据顺序错误。



![img](https:////upload-images.jianshu.io/upload_images/8494967-ad745af0ef9c38a9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

**3.2 保证消息的消费顺序**

（1）rabbitmq
 ①拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。



![img](https:////upload-images.jianshu.io/upload_images/8494967-12a89bd74e2f5135.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理



![img](https:////upload-images.jianshu.io/upload_images/8494967-5edc7ed5df03d12a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

（2）kafka
 ①确保同一个消息发送到同一个partition，一个topic，一个partition，一个consumer，内部单线程消费。



![img](https:////upload-images.jianshu.io/upload_images/8494967-7deff1fc07849dc8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②写N个内存queue，然后N个线程分别消费一个内存queue即可



![img](https:////upload-images.jianshu.io/upload_images/8494967-8fd1fac60635c2c6.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

## seata 原理

**Seata简介**

Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。

**Seata原理和设计**

**定义一个分布式事务**

我们可以把一个分布式事务理解成一个包含了若干分支事务的全局事务，全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个满足ACID的本地事务。这是我们对分布式事务结构的基本认识，与 XA 是一致的。

![img](http://www.macrozheng.com/images/springcloud_seata_07.png)

**协议分布式事务处理过程的三个组件**

- Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚；
- Transaction Manager (TM)： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议；
- Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。

![img](http://www.macrozheng.com/images/springcloud_seata_08.png)

**一个典型的分布式事务过程**

- TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID；
- XID 在微服务调用链路的上下文中传播；
- RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖；
- TM 向 TC 发起针对 XID 的全局提交或回滚决议；
- TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。

![img](http://www.macrozheng.com/images/springcloud_seata_09.png)

#### AT 模式

**前提**

- 基于支持本地 ACID 事务的关系型数据库。
- Java 应用，通过 JDBC 访问数据库。

**整体机制**

两阶段提交协议的演变：

- 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。
- 二阶段：
  - 提交异步化，非常快速地完成。
  - 回滚通过一阶段的回滚日志进行反向补偿。

**写隔离**

- 一阶段本地事务提交前，需要确保先拿到 **全局锁** 。
- 拿不到 **全局锁** ，不能提交本地事务。
- 拿 **全局锁** 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。

以一个示例来说明：

两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000。

tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的 **全局锁** ，本地提交释放本地锁。 tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。本地事务提交前，尝试拿该记录的 **全局锁** ，tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待 **全局锁** 。

![Write-Isolation: Commit](https://img.alicdn.com/tfs/TB1zaknwVY7gK0jSZKzXXaikpXa-702-521.png)

tx1 二阶段全局提交，释放 **全局锁** 。tx2 拿到 **全局锁** 提交本地事务。

![Write-Isolation: Rollback](https://img.alicdn.com/tfs/TB1xW0UwubviK0jSZFNXXaApXXa-718-521.png)

如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚。

此时，如果 tx2 仍在等待该数据的 **全局锁**，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 **全局锁** 等锁超时，放弃 **全局锁** 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功。

因为整个过程 **全局锁** 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 **脏写** 的问题。

**读隔离**

在数据库本地事务隔离级别 **读已提交（Read Committed）** 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 **读未提交（Read Uncommitted）** 。

如果应用在特定场景下，必需要求全局的 **读已提交** ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。

![Read Isolation: SELECT FOR UPDATE](https://img.alicdn.com/tfs/TB138wuwYj1gK0jSZFuXXcrHpXa-724-521.png)

SELECT FOR UPDATE 语句的执行会申请 **全局锁** ，如果 **全局锁** 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 **全局锁** 拿到，即读取的相关数据是 **已提交** 的，才返回。

出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。

**工作机制**

以一个示例来说明整个 AT 分支的工作过程。

业务表：`product`

| Field | Type         | Key  |
| ----- | ------------ | ---- |
| id    | bigint(20)   | PRI  |
| name  | varchar(100) |      |
| since | varchar(100) |      |

AT 分支事务的业务逻辑：

```sql
update product set name = 'GTS' where name = 'TXC';
```

**一阶段**

过程：

1. 解析 SQL：得到 SQL 的类型（UPDATE），表（product），条件（where name = 'TXC'）等相关的信息。
2. 查询前镜像：根据解析得到的条件信息，生成查询语句，定位数据。

```sql
select id, name, since from product where name = 'TXC';
```

得到前镜像：

| id   | name | since |
| ---- | ---- | ----- |
| 1    | TXC  | 2014  |

1. 执行业务 SQL：更新这条记录的 name 为 'GTS'。
2. 查询后镜像：根据前镜像的结果，通过 **主键** 定位数据。

```sql
select id, name, since from product where id = 1;
```

得到后镜像：

| id   | name | since |
| ---- | ---- | ----- |
| 1    | GTS  | 2014  |

1. 插入回滚日志：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 `UNDO_LOG` 表中。

```json
{
	"branchId": 641789253,
	"undoItems": [{
		"afterImage": {
			"rows": [{
				"fields": [{
					"name": "id",
					"type": 4,
					"value": 1
				}, {
					"name": "name",
					"type": 12,
					"value": "GTS"
				}, {
					"name": "since",
					"type": 12,
					"value": "2014"
				}]
			}],
			"tableName": "product"
		},
		"beforeImage": {
			"rows": [{
				"fields": [{
					"name": "id",
					"type": 4,
					"value": 1
				}, {
					"name": "name",
					"type": 12,
					"value": "TXC"
				}, {
					"name": "since",
					"type": 12,
					"value": "2014"
				}]
			}],
			"tableName": "product"
		},
		"sqlType": "UPDATE"
	}],
	"xid": "xid:xxx"
}
```

1. 提交前，向 TC 注册分支：申请 `product` 表中，主键值等于 1 的记录的 **全局锁** 。
2. 本地事务提交：业务数据的更新和前面步骤中生成的 UNDO LOG 一并提交。
3. 将本地事务提交的结果上报给 TC。

**二阶段-回滚**

1. 收到 TC 的分支回滚请求，开启一个本地事务，执行如下操作。
2. 通过 XID 和 Branch ID 查找到相应的 UNDO LOG 记录。
3. 数据校验：拿 UNDO LOG 中的后镜与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理，详细的说明在另外的文档中介绍。
4. 根据 UNDO LOG 中的前镜像和业务 SQL 的相关信息生成并执行回滚的语句：

```sql
update product set name = 'TXC' where id = 1;
```

1. 提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC。

**二阶段-提交**

1. 收到 TC 的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给 TC。
2. 异步任务阶段的分支提交请求将异步和批量地删除相应 UNDO LOG 记录。

**附录**

**回滚日志表**

UNDO_LOG Table：不同数据库在类型上会略有差别。

以 MySQL 为例：

| Field         | Type         |
| ------------- | ------------ |
| branch_id     | bigint PK    |
| xid           | varchar(100) |
| context       | varchar(128) |
| rollback_info | longblob     |
| log_status    | tinyint      |
| log_created   | datetime     |
| log_modified  | datetime     |

```sql
-- 注意此处0.7.0+ 增加字段 context
CREATE TABLE `undo_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(100) NOT NULL,
  `context` varchar(128) NOT NULL,
  `rollback_info` longblob NOT NULL,
  `log_status` int(11) NOT NULL,
  `log_created` datetime NOT NULL,
  `log_modified` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```

#### TCC 模式

回顾总览中的描述：一个分布式的全局事务，整体是 **两阶段提交** 的模型。全局事务是由若干分支事务组成的，分支事务要满足 **两阶段提交** 的模型要求，即需要每个分支事务都具备自己的：

- 一阶段 prepare 行为
- 二阶段 commit 或 rollback 行为

![Overview of a global transaction](https://img.alicdn.com/tfs/TB14Kguw1H2gK0jSZJnXXaT1FXa-853-482.png)

根据两阶段行为模式的不同，我们将分支事务划分为 **Automatic (Branch) Transaction Mode** 和 **Manual (Branch) Transaction Mode**.

AT 模式（[参考链接 TBD](https://seata.io/zh-cn/docs/overview/what-is-seata.html)）基于 **支持本地 ACID 事务** 的 **关系型数据库**：

- 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录。
- 二阶段 commit 行为：马上成功结束，**自动** 异步批量清理回滚日志。
- 二阶段 rollback 行为：通过回滚日志，**自动** 生成补偿操作，完成数据回滚。

相应的，TCC 模式，不依赖于底层数据资源的事务支持：

- 一阶段 prepare 行为：调用 **自定义** 的 prepare 逻辑。
- 二阶段 commit 行为：调用 **自定义** 的 commit 逻辑。
- 二阶段 rollback 行为：调用 **自定义** 的 rollback 逻辑。

所谓 TCC 模式，是指支持把 **自定义** 的分支事务纳入到全局事务的管理中。

#### Saga 模式

Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。

![Saga模式示意图](https://img.alicdn.com/tfs/TB1Y2kuw7T2gK0jSZFkXXcIQFXa-445-444.png)

理论基础：Hector & Kenneth 发表论⽂ Sagas （1987）

**适用场景：**

- 业务流程长、业务流程多
- 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口

**优势：**

- 一阶段提交本地事务，无锁，高性能
- 事件驱动架构，参与者可异步执行，高吞吐
- 补偿服务易于实现

**缺点：**

- 不保证隔离性（应对方案见用户文档）


## redis 整理

#### **1、缓存问题**

**缓存穿透**

指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。

解决方案：

- 对这些不存在的数据缓存一个空数据；
- 对这类请求进行过滤。

**缓存雪崩**

指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。

在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

解决方案：

- 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；
- 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
- 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。

**缓存一致性**

缓存一致性要求数据更新的同时缓存数据也能够实时更新。

解决方案：

- 在数据更新的同时立即去更新缓存；
- 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。

要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。

**缓存 “无底洞” 现象**

指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。

产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。

解决方案：

- 优化批量数据操作命令；
- 减少网络通信次数；
- 降低接入成本，使用长连接 / 连接池，NIO 等。

#### 2：数据类型

STRING、LIST、SET、HASH、ZSET

#### 3：数据结构

字典：dictht 一个散列表结构，使用拉链法解决哈希冲突。

跳跃表：是有序集合的底层实现之一。基于多指针有序链表实现的，可以看成多个有序链表。

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。

#### 4：使用场景

**计数器**

可以对 String 进行自增自减运算，从而实现计数器功能。

Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

**缓存**

将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

**查找表**

例如 DNS 记录就很适合使用 Redis 进行存储。

查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

**消息队列**

List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息

不过最好使用 Kafka、RabbitMQ 等消息中间件。

**会话缓存**

可以使用 Redis 来统一存储多台应用服务器的会话信息。

当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

**分布式锁实现**

在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。

可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。

**其它**

Set 可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet 可以实现有序性操作，从而实现排行榜等功能。

#### 5：持久化

Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。

**RDB 持久化**

将某个时间点的所有数据都存放到硬盘上。

可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。

如果系统发生故障，将会丢失最后一次创建快照之后的数据。

如果数据量很大，保存快照的时间会很长。

**AOF 持久化**

将写命令添加到 AOF 文件（Append Only File）的末尾。

使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：

|   选项   |         同步频率         |
| :------: | :----------------------: |
|  always  |     每个写命令都同步     |
| everysec |       每秒同步一次       |
|    no    | 让操作系统来决定何时同步 |

- always 选项会严重减低服务器的性能；
- everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；
- no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。

随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

#### 6：分片

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0\~1000 的存储到实例 R0 中，用户 id 从 1001\~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。
- 服务器分片：Redis Cluster。



## 认证和会话管理

### JWT 和 session 区别

**Authentication和Authorization的区别：**

Authentication：用户认证，指的是验证用户的身份，例如你希望以小A的身份登录，那么应用程序需要通过用户名和密码确认你真的是小A。

Authorization：授权，指的是确认你的身份之后提供给你权限，例如用户小A可以修改数据，而用户小B只能阅读数据。

由于http协议是无状态的，每一次请求都无状态。当一个用户通过用户名和密码登录了之后，他的下一个请求不会携带任何状态，应用程序无法知道他的身份，那就必须重新认证。因此我们希望用户登录成功之后的每一次http请求，都能够保存他的登录状态。

目前主流的用户认证方法有基于token和基于session两种方式。

#### 基于session的用户认证

基于session的认证流程如下：

![img](https://img2018.cnblogs.com/blog/1500605/201812/1500605-20181208212640810-374114842.png)

 

```
1. 用户输入其登录信息
2. 服务器验证信息是否正确，并创建一个session，然后将其存储在数据库中
3. 服务器为用户生成一个sessionId，将具有sesssionId的Cookie将放置在用户浏览器中
4. 在后续请求中，会根据数据库验证sessionID，如果有效，则接受请求
5. 一旦用户注销应用程序，会话将在客户端和服务器端都被销毁
```

 

#### 基于token(令牌)的认证

最常用的是JSON Web Token（jwt）：

![img](https://img2018.cnblogs.com/blog/1500605/201812/1500605-20181208214418102-1938938567.png)

 

```
1. 用户输入其登录信息
2. 服务器验证信息是否正确，并返回已签名的token
3. token储在客户端，例如存在local storage或cookie中
4. 之后的HTTP请求都将token添加到请求头里
5. 服务器解码JWT，并且如果令牌有效，则接受请求
6. 一旦用户注销，令牌将在客户端被销毁，不需要与服务器进行交互一个关键是，令牌是无状态的。后端服务器不需要保存令牌或当前session的记录。
```

 

**jwt的组成**

#### jwt的认证原理：

一个jwt实际上就是一个字符串，它由三部分组成，**头部**、**载荷**与**签名**，这三个部分都是json格式。

**头部（Header）**

头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。

```
{
  "typ": "JWT",
  "alg": "HS256"
}
```

在这里，我们说明了这是一个JWT，并且我们所用的签名算法是HS256算法。

 

**载荷（Payload）**

载荷可以用来放一些不敏感的信息。

```
{
    "iss": "John Wu JWT",
    "iat": 1441593502,
    "exp": 1441594722,
    "aud": "www.example.com",
    "sub": "jrocket@example.com",
    "from_user": "B",
    "target_user": "A"
}
```

这里面的前五个字段都是由JWT的标准所定义的。

- `iss`: 该JWT的签发者
- `sub`: 该JWT所面向的用户
- `aud`: 接收该JWT的一方
- `exp`(expires): 什么时候过期，这里是一个Unix时间戳
- `iat`(issued at): 在什么时候签发的

把头部和载荷分别进行Base64编码之后得到两个字符串，然后再将这两个编码后的字符串用英文句号`.`连接在一起（头部在前），形成新的字符串：

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0
```

**签名（signature）**

最后，我们将上面拼接完的字符串用HS256算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。加密后的内容也是一个字符串，最后这个字符串就是签名，把这个签名拼接在刚才的字符串后面就能得到完整的jwt。header部分和payload部分如果被篡改，由于篡改者不知道密钥是什么，也无法生成新的signature部分，服务端也就无法通过，在jwt中，消息体是透明的，使用签名可以保证消息不被篡改。

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM
```

 

#### 区别和优缺点

基于session和基于jwt的方式的主要区别就是用户的状态保存的位置，session是保存在服务端的，而jwt是保存在客户端的。

 

**jwt的优点：**

1. 可扩展性好

应用程序分布式部署的情况下，session需要做多机数据共享，通常可以存在数据库或者redis里面。而jwt不需要。

2. 无状态

jwt不在服务端存储任何状态。RESTful API的原则之一是无状态，发出请求时，总会返回带有参数的响应，不会产生附加影响。用户的认证状态引入这种附加影响，这破坏了这一原则。另外jwt的载荷中可以存储一些常用信息，用于交换信息，有效地使用 JWT，可以降低服务器查询数据库的次数。

 

**jwt的缺点：**

1. 安全性

由于jwt的payload是使用base64编码的，并没有加密，因此jwt中不能存储敏感数据。而session的信息是存在服务端的，相对来说更安全。

2. 性能

jwt太长。由于是无状态使用JWT，所有的数据都被放到JWT里，如果还要进行一些数据交换，那载荷会更大，经过编码之后导致jwt非常长，cookie的限制大小一般是4k，cookie很可能放不下，所以jwt一般放在local storage里面。并且用户在系统中的每一次http请求都会把jwt携带在Header里面，http请求的Header可能比Body还要大。而sessionId只是很短的一个字符串，因此使用jwt的http请求比使用session的开销大得多。

3. 一次性

无状态是jwt的特点，但也导致了这个问题，jwt是一次性的。想修改里面的内容，就必须签发一个新的jwt。

（1）无法废弃

通过上面jwt的验证机制可以看出来，一旦签发一个jwt，在到期之前就会始终有效，无法中途废弃。例如你在payload中存储了一些信息，当信息需要更新时，则重新签发一个jwt，但是由于旧的jwt还没过期，拿着这个旧的jwt依旧可以登录，那登录后服务端从jwt中拿到的信息就是过时的。为了解决这个问题，我们就需要在服务端部署额外的逻辑，例如设置一个黑名单，一旦签发了新的jwt，那么旧的就加入黑名单（比如存到redis里面），避免被再次使用。

（2）续签

如果你使用jwt做会话管理，传统的cookie续签方案一般都是框架自带的，session有效期30分钟，30分钟内如果有访问，有效期被刷新至30分钟。一样的道理，要改变jwt的有效时间，就要签发新的jwt。最简单的一种方式是每次请求刷新jwt，即每个http请求都返回一个新的jwt。这个方法不仅暴力不优雅，而且每次请求都要做jwt的加密解密，会带来性能问题。另一种方法是在redis中单独为每个jwt设置过期时间，每次访问时刷新jwt的过期时间。

 

可以看出想要破解jwt一次性的特性，就需要在服务端存储jwt的状态。但是引入 redis 之后，就把无状态的jwt硬生生变成了有状态了，违背了jwt的初衷。而且这个方案和session都差不多了。

 

**总结**

适合使用jwt的场景：

- 有效期短
- 只希望被使用一次

比如，用户注册后发一封邮件让其激活账户，通常邮件中需要有一个链接，这个链接需要具备以下的特性：能够标识用户，该链接具有时效性（通常只允许几小时之内激活），不能被篡改以激活其他可能的账户，一次性的。这种场景就适合使用jwt。

而由于jwt具有一次性的特性。单点登录和会话管理非常不适合用jwt，如果在服务端部署额外的逻辑存储jwt的状态，那还不如使用session。基于session有很多成熟的框架可以开箱即用，但是用jwt还要自己实现逻辑。

 





### SSO (Single sign-on)

通常公司内部会有非常多的平台供大家使用，比如人力资源，代码管理，日志监控，预算申请等等。如果每一个平台都实现自己的用户体系的话无疑是巨大的浪费，所以公司内部会有一套 **公用的用户体系**，用户只要登陆之后，就能够 **访问所有的系统**。这就是 **单点登录**。

`SSO` 是一类 **解决方案** 的统称，而在具体的实施方面，我们有两种策略可供选择：

- **SAML 2.0**
- **OAuth 2.0**

接下来我们区别这 **两种授权方式** 有什么不同。但是在描述 **不同的策略** 之前，我们先叙述几个 **共有的特性**，并且相当重要的概念。

**Authentication VS Authorisation**

- **Authentication:** 身份鉴别，以下简称 **认证**；
- **Authorisation:** 资源访问 **授权**。

**认证** 的作用在于 **认可** 你能够访问系统，用于 **鉴别访问者** 是否是 **合法用户**；而 **授权** 用于决定你有访问 **哪些资源的权限**。

大多数人不会区分这两者的区别，因为站在用户的立场上。而作为系统的设计者来说，这两者是有差别的，这是不同的两个工作职责。我们可以只需要 **认证功能**，而不需要 **授权功能**，甚至不需要自己实现 **认证功能**。而借助 `Google` 的认证系统，即用户可以用 `Google` 的账号进行登陆。

**Authorization Server/Identity Provider(IdP)**

把负责 **认证的服务** 称为 `AuthorizationServer` 或者 `IdentityProvider`，以下简称 `IDP`。

**Service Provider(SP)/Resource Server**

把负责 **提供资源**（`API` 调用）的服务称为 `ResourceServer` 或者 `ServiceProvider`，以下简称 `SP`。

### **SAML 2.0**

1. 还 **未登陆** 的用户 **打开浏览器** 访问你的网站（`SP`），网站 **提供服务** 但是并 **不负责用户认证**。
2. 于是 `SP` 向 `IDP` 发送了一个 `SAML` 认证请求，同时 `SP` 将 **用户浏览器** 重定向到 `IDP`。
3. `IDP` 在验证完来自 `SP` 的 **请求无误** 之后，在浏览器中呈现 **登陆表单** 让用户填写 **用户名** 和 **密码** 进行登陆。
4. 一旦用户登陆成功， `IDP` 会生成一个包含 **用户信息**（**用户名** 或者 **密码**）的 `SAML token`（`SAML token` 又称为 `SAML Assertion`，本质上是 `XML` 节点）。`IDP` 向 `SP` 返回 `token`，并且将 **用户重定向** 到 `SP` (`token` 的返回是在 **重定向步骤** 中实现的，下面会详细说明)。
5. `SP` 对拿到的 `token` 进行验证，并从中解析出 **用户信息**，例如 **用户是谁** 以及 **用户的权限** 有哪些。此时就能够根据这些信息允许用户访问我们网站的内容。

当用户在 `IDP` 登陆成功之后，`IDP` 需要将用户 **再次重定向** 到 `SP` 站点，这一步通常有两个办法：

- `HTTP` 重定向：这并不推荐，因为 **重定向** 的 `URL` 长度 **有限制**，无法携带更长的信息，比如 `SAML Token`。
- `HTTP POST` 请求：这个是更常规的做法，当用户登陆完毕之后渲染出一个表单，用户点击后向 `SP` 提交 `POST` 请求。又或者可以使用 `JavaScript` 向 `SP` 发出一个 `POST` 请求。

如果你的应用是基于 `Web`，那么以上的方案没有任何问题。但如果你开发的是一个 `iOS` 或者 `Android` 的手机应用，那么问题就来了：

1. 用户在 `iPhone` 上打开应用，此时用户需要通过 `IDP` 进行认证。
2. 应用跳转至 `Safari` 浏览器，在登陆认证完毕之后，需要通过 `HTTP POST` 的形式将 `token` 返回至 **手机应用**。

虽然 `POST` 的 `url` 可以 **拉起应用**，但是 **手机应用** 无法解析 `POST` 的内容，我们也就无法读取 `SAML Token`。

> 当然还是有办法的，比如在 `IDP` **授权阶段** 不跳转至系统的 `Safari` 浏览器，在 **内嵌** 的 `Webview` 中解决，在想方设法从 `Webview` 中提取 `token`，或者利用 **代理服务器**。

无论如何，`SAML 2.0` 并 **不适用** 于当下 **跨平台** 的场景，这也许与它产生的年代也有关系，它诞生于 `2005` 年，在那个时刻 `HTTP POST` 确实是最好的选择方案。

### OAuth 2.0

我们先简单了解 `SSO` 下的 `OAuth2.0` 的流程。

1. 用户通过 **客户端**（可以是 **浏览器** 也可以是 **手机应用**）想要访问 `SP` 上的资源，但是 `SP` 告诉用户需要进行 **认证**，将用户 **重定向** 至 `IDP`。
2. `IDP` 向 **用户** 询问 `SP` 是否可以访问 **用户信息**。如果用户同意，`IDP` 向 **客户端** 返回 `authorization code`。
3. 客户端拿到 `authorization code` 向 `IDP` 交换 `access token`，并拿着 `access token` 向 `SP` 请求资源。
4. `SP` 接受到请求之后，拿着附带的 `token` 向 `IDP` 验证 **用户的身份**。确认身份无误后，`SP` 向 **客户端** 发放相关资源。

那么 `OAuth` 是如何避免 `SAML` 流程下 **无法解析** `POST` 内容的信息的呢？

- 一方面是用户从 `IDP` 返回 **客户端** 的方式，也是通过 `URL` 重定向，这里的 `URL` 允许 **自定义** `schema`，所以即使在 **手机** 上也能 **拉起应用**；
- 另一方面因为 `IDP` 向 **客户端** 传递的是 `authorization code`，而不是 `XML` 信息，所以 `code` 可以很轻易的附着在 **重定向** `URL` 上进行传递。

但以上的 `SSO` 流程体现不出 `OAuth` 的本意。`OAuth` 的本意是 **一个应用** 允许 **另一个应用** 在 **用户授权** 的情况下 **访问自己的数据**。

`OAuth` 的设计本意更倾向于 **授权而非认证**（当然授权用户信息就间接实现了认证），虽然 `Google` 的 `OAuth 2.0 API` 同时支持 **授权** 和 **认证**。所以你在使用 `Facebook` 或者 `Gmail` 账号登陆第三方站点时，会出现 **授权对话框**，告诉你 **第三方站点** 可以访问你的哪些信息，需要征得你的同意。

在上面 `SSO` 的 `OAuth` 流程中涉及三方角色: `SP`, `IDP` 以及 `Client`。但在实际工作中 `Client` 可以是不存在的，例如你编写了一个 **后端程序** 定时的通过 `Google API` 从 `Youtube` 拉取最新的节目数据，那么你的 **后端程序** 需要得到 `Youtube` 的 `OAuth` **授权** 即可。

### OAuth VS OpenId

如果你有留心的话，你会在某些站点看到允许以 `OpenID` 的方式登陆，其实也就是以 `Facebook` 账号或者 `Google` 账号登陆站点：

`OpenID` 和 `OAuth` 很像。但本质上来说它们是截然不同的两个东西：

- **OpenID:** 只用于 **身份认证**（`Authentication`），允许你以 **同一个账户** 在 **多个网站登陆**。它仅仅是为你的 **合法身份** 背书，当你以 `Facebook` 账号登陆某个站点之后，该站点 **无权访问** 你的在 `Facebook` 上的 **数据**。
- **OAuth:** 用于 **授权**（`Authorisation`），允许 **被授权方** 访问 **授权方** 的 **用户数据**。

### Refresh Token 和 access token

现在可以回答上面的问题了，为什么我们需要 `refresh token`？

这样的处理是为了 **职责的分离**：

- **refresh token:** 负责 **身份认证**；
- **access token:** 负责 **请求资源**。

虽然 `refresh token` 和 `access token` 都由 `IDP` 发出，但是 `access token` 还要和 `SP` 进行 **数据交换**，如果 **公用的话** 这样就会有 **身份泄露** 的可能。并且 `IDP` 和 `SP` 可能是 **完全不同** 的 **服务提供** 的。而在上文，我们之所以没有这样的顾虑是因为 `IDP` 和 `SP` 都是 `Google`。

### spring session

#### 一、为什么要spring-session

在传统单机web应用中，一般使用tomcat/jetty等web容器时，用户的session都是由容器管理。浏览器使用cookie中记录sessionId，容器根据sessionId判断用户是否存在会话session。这里的限制是，session存储在web容器中，被单台服务器容器管理。

但是网站主键演变，分布式应用和集群是趋势（提高性能）。此时用户的请求可能被负载分发至不同的服务器，此时传统的web容器管理用户会话session的方式即行不通。除非集群或者分布式web应用能够共享session，尽管tomcat等支持这样做。但是这样存在以下两点问题：

- 需要侵入web容器，提高问题的复杂
- web容器之间共享session，集群机器之间势必要交互耦合

基于这些，必须提供新的可靠的集群分布式/集群session的解决方案，突破traditional-session单机限制（即web容器session方式，下面简称traditional-session），spring-session应用而生。

#### 二、比较traditional-session方案和spring-session方案

下图展示了traditional-session和spring-session的区别

![img](https://img2018.cnblogs.com/blog/1286175/201809/1286175-20180918232306231-326643336.png)

传统模式中，当request进入web容器，根据reqest获取session时，如果web容器中存在session则返回，如果不存在，web容器则创建一个session。然后返回response时，将sessonId作为response的head一并返回给客户端或者浏览器。

但是上节中说明了traditional-session的局限性在于：单机session。在此限制的相反面，即将session从web容器中抽出来，形成独立的模块，以便分布式应用或者集群都能共享，即能解决。

spring-session的核心思想在于此：将session从web容器中剥离，存储在独立的存储服务器中。目前支持多种形式的session存储器：Redis、Database、MogonDB等。session的管理责任委托给spring-session承担。当request进入web容器，根据request获取session时，由spring-session负责存存储器中获取session，如果存在则返回，如果不存在则创建并持久化至存储器中。

#### 三、JSR340规范与spring-session的透明继承

JSR340是Java Servlet 3.1的规范提案，其中定义了大量的api，包括：servlet、servletRequest/HttpServletRequest/HttpServletRequestWrapper、servletResponse/HttpServletResponse/HttpServletResponseWrapper、Filter、Session等，是标准的web容器需要遵循的规约，如tomcat/jetty/weblogic等等。

在日常的应用开发中，develpers也在频繁的使用servlet-api，比如：

以下的方式获取请求的session：

```
HttpServletRequest request = ...
HttpSession session = request.getSession(false);
```

其中HttpServletRequest和HttpSession都是servlet规范中定义的接口，web容器实现的标准。那如果引入spring-session，要如何获取session？

- 遵循servlet规范，同样方式获取session，对应用代码无侵入且对于developers透明化
- 全新实现一套session规范，定义一套新的api和session管理机制

两种方案都可以实现，但是显然第一种更友好，且具有兼容性。spring-session正是第一种方案的实现。

实现第一种方案的关键点在于做到透明和兼容

- 接口适配：仍然使用HttpServletRequest获取session，获取到的session仍然是HttpSession类型——**适配器模式**
- 类型包装增强：Session不能存储在web容器内，要外化存储——**装饰模式**

让人兴奋的是，以上的需求在Servlet规范中的扩展性都是予以支持！Servlet规范中定义一系列的接口都是支持扩展，同时提供Filter支撑扩展点。建议阅读《JavaTM Servlet Specification》。

热脑活动结束，下面章节正式进入今天的主题：**spring-session揭秘**

#### 四、Spring Session 探索

主要从以下两个方面来说spring-session：

- 特点
- 工作原理

**一.特点**

spring-session在无需绑定web容器的情况下提供对集群session的支持。并提供对以下情况的透明集成：

- HttpSession：容许替换web容器的HttpSession
- WebSocket：使用WebSocket通信时，提供Session的活跃
- WebSession：容许以应用中立的方式替换webflux的webSession

**二.工作原理**

再详细阅读源码之前先来看张图，介绍下spring-session中的核心模块以及之间的交互。

![img](https://img2018.cnblogs.com/blog/1286175/201809/1286175-20180918232339701-1747137442.png)

spring-session分为以下核心模块：

- SessionRepositoryFilter：Servlet规范中Filter的实现，用来切换HttpSession至Spring Session，包装HttpServletRequest和HttpServletResponse
- HttpServerletRequest/HttpServletResponse/HttpSessionWrapper包装器：包装原有的HttpServletRequest、HttpServletResponse和Spring Session，实现切换Session和透明继承HttpSession的关键之所在
- Session：Spring Session模块
- SessionRepository：管理Spring Session的模块
- HttpSessionStrategy：映射HttpRequst和HttpResponse到Session的策略

#### 五、spring session 提供功能

**特征**

Spring Session使支持集群会话变得很简单，而不必依赖于特定于应用程序容器的解决方案。它还提供了透明的集成：

- `HttpSession` -允许以应用程序容器（即Tomcat）中立的方式替换HttpSession，并支持在标头中提供会话ID以与RESTful API一起使用
- `WebSocket` -提供了在接收WebSocket消息时保持HttpSession存活的功能
- `WebSession` -允许以与应用程序容器无关的方式替换Spring WebFlux的WebSession

**模块**

Spring Session由以下模块组成：

- Spring Session Core-提供核心的Spring Session功能和API
- Spring Session Data Redis-提供由Redis支持的SessionRepository和ReactiveSessionRepository实现以及配置支持
- Spring Session JDBC-提供由关系数据库支持的SessionRepository实现和配置支持
- Spring Session Hazelcast-提供由Hazelcast支持的SessionRepository实现和配置支持

**功能**

会话超时、session共享、一个账号只能同时在线一个、集群session

### spring security

**Spring Security 模块**

- **核心模块** - spring-security-core.jar：包含核心验证和访问控制类和接口，远程支持的基本配置API，是基本模块
- **远程调用** - spring-security-remoting.jar：提供与 Spring Remoting 集成
- **网页** - spring-security-web.jar：包括网站安全的模块，提供网站认证服务和基于URL访问控制
- **配置** - spring-security-config.jar：包含安全命令空间解析代码，若使用XML进行配置则需要
- **LDAP** - spring-security-ldap.jar：LDAP 验证和配置，若需要LDAP验证和管理LDAP用户实体
- **ACL访问控制表** - spring-security-acl.jar：ACL专门领域对象的实现
- **CAS** - spring-security-cas.jar：CAS客户端继承，若想用CAS的SSO服务器网页验证
- **OpenID** - spring-security-openid.jar：OpenID网页验证支持
- **Test** - spring-security-test.jar：支持Spring Security的测试

**会话管理**

**Spring Security**提供的会话并发控制是基于内存实现的，在集群部署时如果想要使用会话并发控制，则必须进行适配。 session共享，本质上就是存储容器的变动，但如何得到最优存取结构、如何准确清理过期会话，以及如何整合**WebSocket**等无法回避。**Spring Session**就是专门用于解决集群会话问题的，它不仅为集群会话提供了非常完善的支持，与**Spring Security**的整合也有专门的实现。 **Spring Session**支持多种类型的存储容器，包括**Redis**、**MongoDB**等。由于接下来的整合都是基于**Redis**的，所以大家可以自行准备**Redis**测试环境，具体如何安装不再赘述。

**登录支持**

支持oauth2的四种授权模式登录、用户名密码加图形验证码登录、手机号加密码登录、openId登录、第三方系统单点登录（扫码登录、人脸登录、指纹登录、虹膜登录）



## 注册中心



|                 | **Nacos**                  | **Eureka**  | **Consul**        | **Zookeeper** |
| :-------------- | :------------------------- | :---------- | :---------------- | :------------ |
| 一致性协议      | CP+AP                      | AP          | CP                | CP            |
| 健康检查        | TCP/HTTP/MYSQL/Client Beat | Client Beat | TCP/HTTP/gRPC/Cmd | Keep Alive    |
| 负载均衡策略    | 权重/ metadata/Selector    | Ribbon      | Fabio             | —             |
| 雪崩保护        | 有                         | 有          | 无                | 无            |
| 自动注销实例    | 支持                       | 支持        | 支持              | 支持          |
| 访问协议        | HTTP/DNS                   | HTTP        | HTTP/DNS          | TCP           |
| 监听支持        | 支持                       | 支持        | 支持              | 支持          |
| 多数据中心      | 支持                       | 支持        | 支持              | 不支持        |
| 跨注册中心同步  | 支持                       | 不支持      | 支持              | 不支持        |
| SpringCloud集成 | 支持                       | 支持        | 支持              | 支持          |
| Dubbo集成       | 支持                       | 不支持      | 支持              | 支持          |
| K8S集成         | 支持                       | 不支持      | 支持              | 不支持        |





## 数据库整理

### 1：事务

**1. 原子性（Atomicity）**

事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。

回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

**2. 一致性（Consistency）**

数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。在原子性和隔离性的基础上保证一致性。

**3. 隔离性（Isolation）**

一个事务所做的修改在最终提交以前，对其它事务是不可见的。

**4. 持久性（Durability）**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

系统发生奔溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。

**四、隔离级别**

**未提交读（READ UNCOMMITTED）**

事务中的修改，即使没有提交，对其它事务也是可见的。

**提交读（READ COMMITTED）**

一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。

**可重复读（REPEATABLE READ）**

保证在同一个事务中多次读取同一数据的结果是一样的。

**可串行化（SERIALIZABLE）**

强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。

该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。

----

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207223400787.png"/> </div><br>

### 2：索引

#### 单列索引 与 复合索引

只包含一个字段的索引叫做单列索引，包含两个或以上字段的索引叫做复合索引（或组合索引）。建立复合索引时，字段的顺序极其重要。

下面这个SQL语句在 列X，列Y，列Z 上建立了一个复合索引。

```mysql
CREATE INDEX 索引名 ON 表名(列名X, 列名Y, 列名Z);
```

其实这相当于建立了三个索引，分别是：

1、单列索引（列X） 2、复合索引（列X, 列Y） 3、复合索引（列X，列Y，列Z）。

#### 唯一索引 与 主键

唯一索引是在表上一个或者多个字段组合建立的索引，这个（或这几个）字段的值组合起来在表中不可以重复。一张表可以建立任意多个唯一索引，但一般只建立一个。

主键是一种特殊的唯一索引，区别在于，唯一索引列允许null值，而主键列不允许为null值。一张表最多建立一个主键，也可以不建立主键。

#### 聚簇索引、非聚簇索引、主键

在《数据库原理》一书中是这么解释聚簇索引和非聚簇索引的区别的：

聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。

怎么理解呢？

聚簇索引的顺序，就是数据在硬盘上的物理顺序。一般情况下主键就是默认的聚簇索引。

一张表只允许存在一个聚簇索引，因为真实数据的物理顺序只能有一种。如果一张表上还没有聚簇索引，为它新创建聚簇索引时，就需要对已有数据重新进行排序，所以对表进行修改速度较慢是聚簇索引的缺点，对于经常更新的列不宜建立聚簇索引。

聚簇索引性能最好，因为一旦具有第一个索引值的记录被找到，具有连续索引值的记录也一定物理地紧跟其后。一张表只能有一个聚簇索引，所以非常珍贵，必须慎重设置，一般要根据这个表最常用的SQL查询方式选择某个（或多个）字段作为聚簇索引（或复合聚簇索引）。

聚簇索引默认是主键，如果表中没有定义主键，InnoDB[[1\]](https://zhuanlan.zhihu.com/p/66553466?utm_source=wechat_session&utm_medium=social&utm_oi=861319674003066880#ref_77889_1)会选择一个唯一的非空索引代替（“唯一的非空索引”是指列不能出现null值的唯一索引，跟主键性质一样）。如果没有这样的索引，InnoDB会隐式地定义一个主键来作为聚簇索引。

#### 聚簇索引 与 唯一索引

严格来说，聚簇索引不一定是唯一索引，聚簇索引的索引值并不要求是唯一的，唯一聚簇索引才是！在一个有聚簇索引的列上是可以插入两个或多个相同值的，这些相同值在硬盘上的物理排序与聚簇索引的排序相同，仅此而已。

#### 聚簇索引与非聚簇索引（也叫二级索引）

**聚簇索引**：也叫主索引，一级索引，一个表只能有一个聚簇索引，主索引的叶子节点 data 域记录着完整的数据记录。

**非聚簇索引**：也叫辅助索引，二级索引，辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

**通俗点讲**

- 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
- 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因

澄清一个概念：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值

**聚簇索引默认是主键**，如果表中没有定义主键，InnoDB 会选择一个**唯一的非空索引**代替。如果没有这样的索引，InnoDB 会**隐式定义一个主键**来作为聚簇索引。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。**如果你已经设置了主键为聚簇索引，必须先删除主键，然后添加我们想要的聚簇索引，最后恢复设置主键即可**。

**聚簇索引的优势**

看上去聚簇索引的效率明显要低于非聚簇索引，因为**每次使用辅助索引检索都要经过两次B+树查找**，这不是多此一举吗？聚簇索引的优势在哪？

1. 由于**行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问**，不必访问磁盘。这样**主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回**了，**如果按照主键Id来组织数据，获得数据更快**。
2. **辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处**是，**减少了当出现行移动或者数据页分裂时辅助索引的维护工作**，**使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"**。**也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响**。
3. 聚簇索引适合用在排序的场合，非聚簇索引不适合
4. 取出一定范围数据的时候，使用用聚簇索引
5. 二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据
6. 可以把**相关数据保存在一起**。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。

#### 组合索引

组合索引又叫多列索引，复合索引。

**为什么不对每一列创建索引**

- 减少开销
- 覆盖索引
- 效率高

减少开销：假如对col1、col2、col3创建组合索引，相当于创建了（col1）、（col1，col2）、（col1，col2，col3）3个索引

覆盖索引：假如查询SELECT col1, col2, col3 FROM 表名，由于查询的字段存在索引页中，那么可以从索引中直接获取，而不需要回表查询

效率高：对col1、col2、col3三列分别创建索引，MySQL只会选择辨识度高的一列作为索引。假设有100w的数据，一个索引筛选出10%的数据，那么可以筛选出10w的数据；对于组合索引而言，可以筛选出100w*10%*10%*10%=1000条数据

**最左匹配原则**

假设我们创建（col1，col2，col3）这样的一个组合索引，那么相当于对col1列进行排序，也就是我们创建组合索引，以最左边的为准，只要查询条件中带有最左边的列，那么查询就会使用到索引

#### 索引分类

**存储方式区分**

B+Tree 索引、哈希索引、全文索引、空间数据索引

**逻辑区分**

- 普通索引：仅加速查询
- 唯一索引：加速查询 + 列值唯一（可以有null）
- 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个
- 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并
- 全文索引：对文本的内容进行分词，进行搜索





### 3：数据库优化

#### 3.1、索引优化

**1. 独立的列**

在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。

例如下面的查询不能使用 actor_id 列的索引：

```sql
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
```

**2. 多列索引**

在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。

```sql
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

**3. 索引列的顺序**

让选择性最强的索引列放在前面。

索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。

例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。

```sql
SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,
COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,
COUNT(*)
FROM payment;
```

```html
   staff_id_selectivity: 0.0001
customer_id_selectivity: 0.0373
               COUNT(*): 16049
```

**4. 前缀索引**

对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。

前缀长度的选取需要根据索引选择性来确定。

**5. 覆盖索引**

索引包含所有需要查询的字段的值。

具有以下优点：

- 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
- 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
- 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

**索引的优点**

- 大大减少了服务器需要扫描的数据行数。

- 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。

- 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

**索引的使用条件**

- 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；

- 对于中到大型的表，索引就非常有效；

- 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

#### 3.2、查询优化

**使用 Explain 进行分析**

Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有：

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

**优化数据访问**

**1. 减少请求的数据量**

- 只返回必要的列：最好不要使用 SELECT * 语句。
- 只返回必要的行：使用 LIMIT 语句来限制返回的数据。
- 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。

**2. 减少服务器端扫描的行数**

最有效的方式是使用索引来覆盖查询。

**重构查询方式**

**1. 切分大查询**

一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

```sql
DELETE FROM messages WHERE create < DATE_SUB(NOW(), INTERVAL 3 MONTH);
```

```sql
rows_affected = 0
do {
    rows_affected = do_query(
    "DELETE FROM messages WHERE create  < DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")
} while rows_affected > 0
```

**2. 分解大连接查询**

将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：

- 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
- 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
- 减少锁竞争；
- 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
- 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。

```sql
SELECT * FROM tag
JOIN tag_post ON tag_post.tag_id=tag.id
JOIN post ON tag_post.post_id=post.id
WHERE tag.tag='mysql';
```

```sql
SELECT * FROM tag WHERE tag='mysql';
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
```

#### 3.3、复制

主从复制、读写分离

#### 3.4、切分

分库分表：水平切分、垂直切分

**Sharding 策略**

- 哈希取模：hash(key) % N；
- 范围：可以是 ID 范围也可以是时间范围；
- 映射表：使用单独的一个数据库来存储映射关系。

**Sharding 存在的问题**

**1. 事务问题**

使用分布式事务来解决，比如 XA 接口。

**2. 连接**

可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。

**3. ID 唯一性**

- 使用全局唯一 ID（GUID）
- 为每个分片指定一个 ID 范围
- 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)





## 各种锁的简介





## 进程、线程、协程

NIO

netty

reactor、Proactor

从这两图可以看出，NIO的单线程能处理连接的数量比BIO要高出很多，而为什么单线程能处理更多的连接呢？原因就是图二中出现的`Selector`。
 当一个连接建立之后，他有两个步骤要做，第一步是接收完客户端发过来的全部数据，第二步是服务端处理完请求业务之后返回response给客户端。NIO和BIO的区别主要是在第一步。
 在BIO中，等待客户端发数据这个过程是阻塞的，这样就造成了一个线程只能处理一个请求的情况，而机器能支持的最大线程数是有限的，这就是为什么BIO不能支持高并发的原因。
 而NIO中，当一个Socket建立好之后，Thread并不会阻塞去接受这个Socket，而是将这个请求交给Selector，Selector会不断的去遍历所有的Socket，一旦有一个Socket建立完成，他会通知Thread，然后Thread处理完数据再返回给客户端——**这个过程是不阻塞的**，这样就能让一个Thread处理更多的请求了。

**Netty为什么传输快**

Netty的传输快其实也是依赖了NIO的一个特性——*零拷贝*。我们知道，Java的内存有堆内存、栈内存和字符串常量池等等，其中堆内存是占用内存空间最大的一块，也是Java对象存放的地方，一般我们的数据如果需要从IO读取到堆内存，中间需要经过Socket缓冲区，也就是说一个数据会被拷贝两次才能到达他的的终点，如果数据量大，就会造成不必要的资源浪费。
 Netty针对这种情况，使用了NIO中的另一大特性——零拷贝，当他需要接收数据的时候，他会在堆内存之外开辟一块内存，数据就直接从IO读到了那块内存中去，在netty里面通过ByteBuf可以直接对这些数据进行直接操作，从而加快了传输速度。





## 数据结构与容器

1：数据结构层面

2：动态扩容层面

3：数据同步层面



## 内存泄漏与JVM





## 设计模式整理









## 编译器原理



## 并发有多少



## 自我介绍整理





## 描述一个项目

项目背景：

架构设计：

技术难点：



## 优点和缺点





## 要问面试官的问题

1：部门整体业务

2：自己可能的工作内容