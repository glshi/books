## 分布式原理

**1：分布式锁**

数据库的唯一索引、Redis 的 SETNX 指令、Redis 的 RedLock 算法、Zookeeper 的有序节点

**2：分布式事务**

2PC、本地消息表、seata

**3：分布式理论**

CAP、BASE、Paxos、Raft 

## zookeeper 原理

> 简单的说，zookeeper=文件系统+通知机制。Zookeeper维护一个类似文件系统的数据结构。每个子目录项如 NameService 都被称作为 znode，和文件系统一样，我们能够自由的增加、删除 znode，唯一的不同在于znode是可以存储数据的。有四种类型的znode，PERSISTENT-持久化目录节点、PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点、EPHEMERAL-临时目录节点、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点。客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。

**我们能用zookeeper做什么**

**1、 命名服务**

​    这个似乎最简单，在zookeeper的文件系统里创建一个目录，即有唯一的path。

**2、 配置管理**

​    程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。

​                     ![zookeeper简介](http://static.open-open.com/lib/uploadImg/20141108/20141108213345_625.png)

 

**3、 集群管理**

所谓集群管理无在乎两点：是否有**机器退出和加入、选举master**。

​    对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。

​    对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。

​                 ![zookeeper简介](http://static.open-open.com/lib/uploadImg/20141108/20141108213345_947.png)

 

**4、 分布式锁**

​    有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，**一个是保持独占，另一个是控制时序。**

​    对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。厕所有言：来也冲冲，去也冲冲，用完删除掉自己创建的distribute_lock 节点就释放出锁。

​    对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。

​                     ![zookeeper简介](http://static.open-open.com/lib/uploadImg/20141108/20141108213345_5.png)

**5、 队列管理**

两种类型的队列：

1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。

2、队列按照 FIFO 方式进行入队和出队操作。

第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。

第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。         

**ZooKeeper的工作原理**

​    Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。

​    为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上 了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。

每个Server在工作过程中有三种状态：

- LOOKING：当前Server不知道leader是谁，正在搜寻
- LEADING：当前Server即为选举出来的leader
- FOLLOWING：leader已经选举出来，当前Server与之同步

## dubbo 原理

**dubbo**是一个分布式服务中间件，是高性能和透明化的RPC远程服务调用解决方案，主要通过资源调度和服务治理来解决分布式架构下服务资源浪费以提高集群的使用率。核心部分包含：

- 远程通讯：提供多种基于长连接的NIO的抽象封装，包括多种线程模型，序列化方式，以及请求-响应模式的信息交互
- 集群容错：提供基于接口方法的透明化远程调用，包括多协议支持，软负载均衡，失败容错，地址路由，动态配置的集群策略
- 服务发现：基于注册中心目录服务，使服务消费者能动态查找服务提供者，使地址透明，服务提供者可以根据流量平滑增加节点

在深入架构前，先了解一下dubbo的组件角色，如下图： 

- Provider：暴露服务的服务提供方
- Container：服务运行容器
- Registry：服务注册与发现的注册中心
- Consumer：调用远程服务的服务消费方
- Monitor：统计服务调用次数和耗时的监控中心

调用关系分析：

- 服务容器Container负责启动，加载，运行服务提供者。
- 服务提供者Provider在启动时，向注册中心注册自己提供的服务。
- 服务消费者Consumer在启动时，向注册中心订阅自己所需的服务。
- 注册中心Registry返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
- 服务消费者Consumer，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
- 服务消费者Consumer和提供者Provider，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心Monitor。

Dubbo 和 Spring Cloud 有什么区别？

```undefined
1、通信方式不同：Dubbo 使用的是 RPC 通信，而Spring Cloud 使用的是HTTP RESTFul 方式。
2、组成不一样：
dubbo的服务注册中心为Zookeerper，服务监控中心为dubbo-monitor,无消息总线，服务跟踪、批量任务等组件；
spring-cloud的服务注册中心为spring-cloud netflix  enruka，服务监控中心为spring-boot admin,有消息总线，数据流、服务跟踪、批量任务等组件；
```

**dubbo协议**

​     1.采用单一长链接和NIO异步通讯，适合小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。

​     2.Dubbo协议底层默认使用的是netty，性能非常优秀，官方推荐使用此协议。

​     3.不适合传输大数据量的服务，如传输文件，传视频等，除非请求量很低。

​     4.<dubbo:protocol  name="dubbo"  port="20880" />，使用此标签来设置其他协议，默认端口为20880。

**hessian协议**

​     Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现。

## kafka 原理

Kafka是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由LinkedIn公司开发，使用Scala语言编写，目前是Apache的开源项目。

跟RabbitMQ、RocketMQ等目前流行的开源消息中间件相比，Kakfa具有高吞吐、低延迟等特点，在大数据、日志收集等应用场景下被广泛使用。

基本概念：

- broker：Kafka服务器，负责消息存储和转发
- topic：消息类别，Kafka按照topic来分类消息
- partition：topic的分区，一个topic可以包含多个partition，topic消息保存在各个partition上
- offset：消息在日志中的位置，可以理解是消息在partition上的偏移量，也是代表该消息的唯一序号
- Producer：消息生产者
- Consumer：消息消费者
- Consumer Group：消费者分组，每个Consumer必须属于一个group
- Zookeeper：保存着集群broker、topic、partition等meta数据；另外，还负责broker故障发现，partition leader选举，负载均衡等功能

3.1 数据存储设计

3.2 生产者设计

3.3 消费者设计

3.4 Replication设计

3.5 高吞吐设计

3.6  HA 基本原理



## rabbitMq 原理

**为什么使用消息队列**

消息队列用于系统之间解耦，通过高性能消息中间件，提升系统吞吐量，降低导致系统耦合。 当前有各种消息队列，RabbitMQ、Kafka、ActiveMQ等，为什么使用RabbitMQ？ 消息队列从使用场景来分为两类：

- 一类是大数据的数据流处理，数据采集者作为生产者数据通过消息队列从到后端处理。这种场景要求高吞吐高并发，Kafka专门为这种场景设计。
- 另一类是消息高可靠低时延在系统之间传递，这种场景要求可靠性高，消息不能丢；要求时延低。AMQP协议专门为这种场景设计，RabbitMQ是AMQP协议实现者之一，也是当前使用的最广的AMQP消息队列。

**RabbitMQ 基本概念**

上面只是最简单抽象的描述，具体到 RabbitMQ 则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念：

![img](https:////upload-images.jianshu.io/upload_images/5015984-367dd717d89ae5db.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp)

​																				RabbitMQ 内部结构

1. Message
   消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。
2. Publisher
   消息的生产者，也是一个向交换器发布消息的客户端应用程序。
3. Exchange
   交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。
4. Binding
   绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。
5. Queue
   消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。
6. Connection
   网络连接，比如一个TCP连接。
7. Channel
   信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。
8. Consumer
   消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。
9. Virtual Host
   虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。
10. Broker
     表示消息队列服务器实体。

我们先来了解下RabbitMQ中的相关概念，这里以5种消息模式中的`路由模式`为例。

![img](http://www.macrozheng.com/images/rabbitmq_start_01.png)

| 标志   | 中文名        | 英文名   | 描述                                             |
| ------ | ------------- | -------- | ------------------------------------------------ |
| P      | 生产者        | Producer | 消息的发送者，可以将消息发送到交换机             |
| C      | 消费者        | Consumer | 消息的接收者，从队列中获取消息并进行消费         |
| X      | 交换机        | Exchange | 接收生产者发送的消息，并根据路由键发送给指定队列 |
| Q      | 队列          | Queue    | 存储从交换机发来的消息                           |
| type   | 交换机类型    | type     | 不同类型的交换机转发消息方式不同                 |
| fanout | 发布/订阅模式 | fanout   | 广播消息给所有绑定交换机的队列                   |
| direct | 路由模式      | direct   | 根据路由键发送消息                               |
| topic  | 通配符模式    | topic    | 根据路由键的匹配规则发送消息                     |

**5种消息模式**

> 这5种消息模式是构建基于RabbitMQ的消息应用的基础，一定要牢牢掌握它们。学过RabbitMQ的朋友应该了解过这些消息模式的Java实现，这里我们使用Spring AMQP的形式来实现它们。

**简单模式**

> 简单模式是最简单的消息模式，它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。

![img](http://www.macrozheng.com/images/rabbitmq_start_12.png)

**工作模式**

> 工作模式是指向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。

![img](http://www.macrozheng.com/images/rabbitmq_start_15.png)

**发布/订阅模式**

> 发布/订阅模式是指同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。

![img](http://www.macrozheng.com/images/rabbitmq_start_19.png)

**路由模式**

> 路由模式是可以根据`路由键`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过`路由键`绑定到交换机上去，生产者发送消息到交换机，交换机通过`路由键`转发到不同队列，队列绑定的消费者接收并消费消息。

![img](http://www.macrozheng.com/images/rabbitmq_start_23.png)

**通配符模式**

> 通配符模式是可以根据`路由键匹配规则`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过`路由键匹配规则`绑定到交换机上去，生产者发送消息到交换机，交换机通过`路由键匹配规则`转发到不同队列，队列绑定的消费者接收并消费消息。

**特殊匹配符号**

- `*`：只能匹配一个单词；
- `#`：可以匹配零个或多个单词。

![img](http://www.macrozheng.com/images/rabbitmq_start_27.png)

**死信队列DLX**

**`死信队列(DLX Dead-Letter-Exchange)：`**利用DLX，当消息在一个队列中变成死信(dead message)之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。

DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。

当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列。

可以监听这个队列中消息做相应的处理，这个特性可以弥补RabbitMQ3.0之前支持的immediate参数的功能。

**消息变成死信的几种情况：**

- 消息被拒绝(basic.reject/basic.nack)并且requeue=false
- 消息TTL过期
- 队列达到最大长度

**死信队列设置：**需要设置死信队列的exchange和queue，然后通过routing key进行绑定。**只不过我们需要在队列加上一个参数即可**。



## 消息队列

#### 1：消息可靠性

丢数据一般分为两种，一种是mq把消息丢了，一种就是消费时将消息丢了。下面从rabbitmq和kafka分别说一下，丢失数据的场景，
 （1）rabbitmq
 **A:生产者弄丢了数据**
 生产者将数据发送到rabbitmq的时候，可能在传输过程中因为网络等问题而将数据弄丢了。
 **B:rabbitmq自己丢了数据**
 如果没有开启rabbitmq的持久化，那么rabbitmq一旦重启，那么数据就丢了。所依必须开启持久化将消息持久化到磁盘，这样就算rabbitmq挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢失。除非极其罕见的情况，rabbitmq还没来得及持久化自己就挂了，这样可能导致一部分数据丢失。
 **C：消费端弄丢了数据**
 主要是因为消费者消费时，刚消费到，还没有处理，结果消费者就挂了，这样你重启之后，rabbitmq就认为你已经消费过了，然后就丢了数据。

![img](https:////upload-images.jianshu.io/upload_images/8494967-a279a2bf41cfc412.png?imageMogr2/auto-orient/strip|imageView2/2/w/1052/format/webp)


 （2）kafka
**A:生产者弄丢了数据**
 生产者没有设置相应的策略，发送过程中丢失数据。
**B:kafka弄丢了数据**
 比较常见的一个场景，就是kafka的某个broker宕机了，然后重新选举partition的leader时。如果此时follower还没来得及同步数据，leader就挂了，然后某个follower成为了leader，他就少了一部分数据。
**C:消费者弄丢了数据**
 消费者消费到了这个数据，然后消费之自动提交了offset，让kafka知道你已经消费了这个消息，当你准备处理这个消息时，自己挂掉了，那么这条消息就丢了。



![img](https:////upload-images.jianshu.io/upload_images/8494967-1c745e1dbb3b9143.png?imageMogr2/auto-orient/strip|imageView2/2/w/816/format/webp)



**3.如何防止消息丢失**

（1）rabbitmq
 **A:生产者丢失消息**
 ①：可以选择使用rabbitmq提供是事物功能，就是生产者在发送数据之前开启事物，然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会受到异常报错，这时就可以回滚事物，然后尝试重新发送；如果收到了消息，那么就可以提交事物。



```cpp
  channel.txSelect();//开启事物
  try{
      //发送消息
  }catch(Exection e){
      channel.txRollback()；//回滚事物
      //重新提交
  }
```

**缺点：**rabbitmq事物已开启，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。

②：可以开启confirm模式。在生产者哪里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如何写入了rabbitmq之中，rabbitmq会给你回传一个ack消息，告诉你这个消息发送OK了；如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息失败了，你可以进行重试。而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么你可以进行重发。



```cpp
    //开启confirm
    channel.confirm();
    //发送成功回调
    public void ack(String messageId){
      
    }

    // 发送失败回调
    public void nack(String messageId){
        //重发该消息
    }
```

**二者不同**
 事务机制是同步的，你提交了一个事物之后会阻塞住，但是confirm机制是异步的，发送消息之后可以接着发送下一个消息，然后rabbitmq会回调告知成功与否。
 一般在生产者这块避免丢失，都是用confirm机制。
 **B:rabbitmq自己弄丢了数据**
 设置消息持久化到磁盘。设置持久化有两个步骤：
 ①创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里面的数据。
 ②发送消息的时候讲消息的deliveryMode设置为2，这样消息就会被设为持久化方式，此时rabbitmq就会将消息持久化到磁盘上。
 必须要同时开启这两个才可以。

而且持久化可以跟生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前rabbitmq挂了，数据丢了，生产者收不到ack回调也会进行消息重发。
 **C:消费者弄丢了数据**
 使用rabbitmq提供的ack机制，首先关闭rabbitmq的自动ack，然后每次在确保处理完这个消息之后，在代码里手动调用ack。这样就可以避免消息还没有处理完就ack。

（2）kafka
 **A:消费端弄丢了数据**
 关闭自动提交offset，在自己处理完毕之后手动提交offset，这样就不会丢失数据。
 **B:kafka弄丢了数据**
 一般要求设置4个参数来保证消息不丢失：
 ①给topic设置 **replication.factor**参数：这个值必须大于1，表示要求每个partition必须至少有2个副本。

②在kafka服务端设置**min.isync.replicas**参数：这个值必须大于1，表示 要求一个leader至少感知到有至少一个follower在跟自己保持联系正常同步数据，这样才能保证leader挂了之后还有一个follower。

③在生产者端设置**acks=all**：表示 要求每条每条数据，必须是写入所有replica副本之后，才能认为是写入成功了

④在生产者端设置**retries=MAX**(很大的一个值，表示无限重试)：表示 这个是要求一旦写入事变，就无限重试
 **C：生产者弄丢了数据**
 如果按照上面设置了ack=all，则一定不会丢失数据，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。



#### 2：消息重复消费

要保证消息的幂等性，这个要结合业务的类型来进行处理。下面提供几个思路供参考：

1. 可在内存中维护一个set，只要从消息队列里面获取到一个消息，先查询这个消息在不在set里面，如果在表示已消费过，直接丢弃；如果不在，则在消费后将其加入set当中。
2. 如何要写数据库，可以拿唯一键先去数据库查询一下，如果不存在在写，如果存在直接更新或者丢弃消息。
   如果是写redis那没有问题，每次都是set，天然的幂等性。
3. 让生产者发送消息时，每条消息加一个全局的唯一id，然后消费时，将该id保存到redis里面。消费时先去redis里面查一下有么有，没有再消费。
4. 数据库操作可以设置唯一键，防止重复数据的插入，这样插入只会报错而不会插入重复数据。

#### 3：消息顺序执行

**3.1 出现顺序错乱的场景**

（1）rabbitmq
 ①一个queue，有多个consumer去消费，这样就会造成顺序的错误，consumer从MQ里面读取数据是有序的，但是每个consumer的执行时间是不固定的，无法保证先读到消息的consumer一定先完成操作，这样就会出现消息并没有按照顺序执行，造成数据顺序错误。



![img](https:////upload-images.jianshu.io/upload_images/8494967-e450c6cb00e84866.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②一个queue对应一个consumer，但是consumer里面进行了多线程消费，这样也会造成消息消费顺序错误。



![img](https:////upload-images.jianshu.io/upload_images/8494967-65a77852d22d0833.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

（2）kafka
 ①kafka一个topic，一个partition，一个consumer，但是consumer内部进行多线程消费，这样数据也会出现顺序错乱问题。



![img](https:////upload-images.jianshu.io/upload_images/8494967-8cc85c5a6cc9bbf5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②具有顺序的数据写入到了不同的partition里面，不同的消费者去消费，但是每个consumer的执行时间是不固定的，无法保证先读到消息的consumer一定先完成操作，这样就会出现消息并没有按照顺序执行，造成数据顺序错误。



![img](https:////upload-images.jianshu.io/upload_images/8494967-ad745af0ef9c38a9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

**3.2 保证消息的消费顺序**

（1）rabbitmq
 ①拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。



![img](https:////upload-images.jianshu.io/upload_images/8494967-12a89bd74e2f5135.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理



![img](https:////upload-images.jianshu.io/upload_images/8494967-5edc7ed5df03d12a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

（2）kafka
 ①确保同一个消息发送到同一个partition，一个topic，一个partition，一个consumer，内部单线程消费。



![img](https:////upload-images.jianshu.io/upload_images/8494967-7deff1fc07849dc8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

②写N个内存queue，然后N个线程分别消费一个内存queue即可



![img](https:////upload-images.jianshu.io/upload_images/8494967-8fd1fac60635c2c6.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

## seata 原理

**Seata简介**

Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。

**Seata原理和设计**

**定义一个分布式事务**

我们可以把一个分布式事务理解成一个包含了若干分支事务的全局事务，全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个满足ACID的本地事务。这是我们对分布式事务结构的基本认识，与 XA 是一致的。

![img](http://www.macrozheng.com/images/springcloud_seata_07.png)

**协议分布式事务处理过程的三个组件**

- Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚；
- Transaction Manager (TM)： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议；
- Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。

![img](http://www.macrozheng.com/images/springcloud_seata_08.png)

**一个典型的分布式事务过程**

- TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID；
- XID 在微服务调用链路的上下文中传播；
- RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖；
- TM 向 TC 发起针对 XID 的全局提交或回滚决议；
- TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。

![img](http://www.macrozheng.com/images/springcloud_seata_09.png)

#### AT 模式

**前提**

- 基于支持本地 ACID 事务的关系型数据库。
- Java 应用，通过 JDBC 访问数据库。

**整体机制**

两阶段提交协议的演变：

- 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。
- 二阶段：
  - 提交异步化，非常快速地完成。
  - 回滚通过一阶段的回滚日志进行反向补偿。

**写隔离**

- 一阶段本地事务提交前，需要确保先拿到 **全局锁** 。
- 拿不到 **全局锁** ，不能提交本地事务。
- 拿 **全局锁** 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。

以一个示例来说明：

两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000。

tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的 **全局锁** ，本地提交释放本地锁。 tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。本地事务提交前，尝试拿该记录的 **全局锁** ，tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待 **全局锁** 。

![Write-Isolation: Commit](https://img.alicdn.com/tfs/TB1zaknwVY7gK0jSZKzXXaikpXa-702-521.png)

tx1 二阶段全局提交，释放 **全局锁** 。tx2 拿到 **全局锁** 提交本地事务。

![Write-Isolation: Rollback](https://img.alicdn.com/tfs/TB1xW0UwubviK0jSZFNXXaApXXa-718-521.png)

如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚。

此时，如果 tx2 仍在等待该数据的 **全局锁**，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 **全局锁** 等锁超时，放弃 **全局锁** 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功。

因为整个过程 **全局锁** 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 **脏写** 的问题。

**读隔离**

在数据库本地事务隔离级别 **读已提交（Read Committed）** 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 **读未提交（Read Uncommitted）** 。

如果应用在特定场景下，必需要求全局的 **读已提交** ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。

![Read Isolation: SELECT FOR UPDATE](https://img.alicdn.com/tfs/TB138wuwYj1gK0jSZFuXXcrHpXa-724-521.png)

SELECT FOR UPDATE 语句的执行会申请 **全局锁** ，如果 **全局锁** 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 **全局锁** 拿到，即读取的相关数据是 **已提交** 的，才返回。

出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。

**工作机制**

以一个示例来说明整个 AT 分支的工作过程。

业务表：`product`

| Field | Type         | Key  |
| ----- | ------------ | ---- |
| id    | bigint(20)   | PRI  |
| name  | varchar(100) |      |
| since | varchar(100) |      |

AT 分支事务的业务逻辑：

```sql
update product set name = 'GTS' where name = 'TXC';
```

**一阶段**

过程：

1. 解析 SQL：得到 SQL 的类型（UPDATE），表（product），条件（where name = 'TXC'）等相关的信息。
2. 查询前镜像：根据解析得到的条件信息，生成查询语句，定位数据。

```sql
select id, name, since from product where name = 'TXC';
```

得到前镜像：

| id   | name | since |
| ---- | ---- | ----- |
| 1    | TXC  | 2014  |

1. 执行业务 SQL：更新这条记录的 name 为 'GTS'。
2. 查询后镜像：根据前镜像的结果，通过 **主键** 定位数据。

```sql
select id, name, since from product where id = 1;
```

得到后镜像：

| id   | name | since |
| ---- | ---- | ----- |
| 1    | GTS  | 2014  |

1. 插入回滚日志：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 `UNDO_LOG` 表中。

```json
{
	"branchId": 641789253,
	"undoItems": [{
		"afterImage": {
			"rows": [{
				"fields": [{
					"name": "id",
					"type": 4,
					"value": 1
				}, {
					"name": "name",
					"type": 12,
					"value": "GTS"
				}, {
					"name": "since",
					"type": 12,
					"value": "2014"
				}]
			}],
			"tableName": "product"
		},
		"beforeImage": {
			"rows": [{
				"fields": [{
					"name": "id",
					"type": 4,
					"value": 1
				}, {
					"name": "name",
					"type": 12,
					"value": "TXC"
				}, {
					"name": "since",
					"type": 12,
					"value": "2014"
				}]
			}],
			"tableName": "product"
		},
		"sqlType": "UPDATE"
	}],
	"xid": "xid:xxx"
}
```

1. 提交前，向 TC 注册分支：申请 `product` 表中，主键值等于 1 的记录的 **全局锁** 。
2. 本地事务提交：业务数据的更新和前面步骤中生成的 UNDO LOG 一并提交。
3. 将本地事务提交的结果上报给 TC。

**二阶段-回滚**

1. 收到 TC 的分支回滚请求，开启一个本地事务，执行如下操作。
2. 通过 XID 和 Branch ID 查找到相应的 UNDO LOG 记录。
3. 数据校验：拿 UNDO LOG 中的后镜与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理，详细的说明在另外的文档中介绍。
4. 根据 UNDO LOG 中的前镜像和业务 SQL 的相关信息生成并执行回滚的语句：

```sql
update product set name = 'TXC' where id = 1;
```

1. 提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC。

**二阶段-提交**

1. 收到 TC 的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给 TC。
2. 异步任务阶段的分支提交请求将异步和批量地删除相应 UNDO LOG 记录。

**附录**

**回滚日志表**

UNDO_LOG Table：不同数据库在类型上会略有差别。

以 MySQL 为例：

| Field         | Type         |
| ------------- | ------------ |
| branch_id     | bigint PK    |
| xid           | varchar(100) |
| context       | varchar(128) |
| rollback_info | longblob     |
| log_status    | tinyint      |
| log_created   | datetime     |
| log_modified  | datetime     |

```sql
-- 注意此处0.7.0+ 增加字段 context
CREATE TABLE `undo_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(100) NOT NULL,
  `context` varchar(128) NOT NULL,
  `rollback_info` longblob NOT NULL,
  `log_status` int(11) NOT NULL,
  `log_created` datetime NOT NULL,
  `log_modified` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```

#### TCC 模式

回顾总览中的描述：一个分布式的全局事务，整体是 **两阶段提交** 的模型。全局事务是由若干分支事务组成的，分支事务要满足 **两阶段提交** 的模型要求，即需要每个分支事务都具备自己的：

- 一阶段 prepare 行为
- 二阶段 commit 或 rollback 行为

![Overview of a global transaction](https://img.alicdn.com/tfs/TB14Kguw1H2gK0jSZJnXXaT1FXa-853-482.png)

根据两阶段行为模式的不同，我们将分支事务划分为 **Automatic (Branch) Transaction Mode** 和 **Manual (Branch) Transaction Mode**.

AT 模式（[参考链接 TBD](https://seata.io/zh-cn/docs/overview/what-is-seata.html)）基于 **支持本地 ACID 事务** 的 **关系型数据库**：

- 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录。
- 二阶段 commit 行为：马上成功结束，**自动** 异步批量清理回滚日志。
- 二阶段 rollback 行为：通过回滚日志，**自动** 生成补偿操作，完成数据回滚。

相应的，TCC 模式，不依赖于底层数据资源的事务支持：

- 一阶段 prepare 行为：调用 **自定义** 的 prepare 逻辑。
- 二阶段 commit 行为：调用 **自定义** 的 commit 逻辑。
- 二阶段 rollback 行为：调用 **自定义** 的 rollback 逻辑。

所谓 TCC 模式，是指支持把 **自定义** 的分支事务纳入到全局事务的管理中。

#### Saga 模式

Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。

![Saga模式示意图](https://img.alicdn.com/tfs/TB1Y2kuw7T2gK0jSZFkXXcIQFXa-445-444.png)

理论基础：Hector & Kenneth 发表论⽂ Sagas （1987）

**适用场景：**

- 业务流程长、业务流程多
- 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口

**优势：**

- 一阶段提交本地事务，无锁，高性能
- 事件驱动架构，参与者可异步执行，高吞吐
- 补偿服务易于实现

**缺点：**

- 不保证隔离性（应对方案见用户文档）


## redis 整理

#### **1、缓存问题**

**缓存穿透**

指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。

解决方案：

- 对这些不存在的数据缓存一个空数据；
- 对这类请求进行过滤。

**缓存雪崩**

指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。

在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

解决方案：

- 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；
- 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
- 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。

**缓存一致性**

缓存一致性要求数据更新的同时缓存数据也能够实时更新。

解决方案：

- 在数据更新的同时立即去更新缓存；
- 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。

要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。

**缓存 “无底洞” 现象**

指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。

产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。

解决方案：

- 优化批量数据操作命令；
- 减少网络通信次数；
- 降低接入成本，使用长连接 / 连接池，NIO 等。

#### 2：数据类型

STRING、LIST、SET、HASH、ZSET

#### 3：数据结构

字典：dictht 一个散列表结构，使用拉链法解决哈希冲突。

跳跃表：是有序集合的底层实现之一。基于多指针有序链表实现的，可以看成多个有序链表。

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。

#### 4：使用场景

**计数器**

可以对 String 进行自增自减运算，从而实现计数器功能。

Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

**缓存**

将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

**查找表**

例如 DNS 记录就很适合使用 Redis 进行存储。

查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

**消息队列**

List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息

不过最好使用 Kafka、RabbitMQ 等消息中间件。

**会话缓存**

可以使用 Redis 来统一存储多台应用服务器的会话信息。

当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

**分布式锁实现**

在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。

可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。

**其它**

Set 可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet 可以实现有序性操作，从而实现排行榜等功能。

#### 5：持久化

Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。

**RDB 持久化**

将某个时间点的所有数据都存放到硬盘上。

可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。

如果系统发生故障，将会丢失最后一次创建快照之后的数据。

如果数据量很大，保存快照的时间会很长。

**AOF 持久化**

将写命令添加到 AOF 文件（Append Only File）的末尾。

使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：

|   选项   |         同步频率         |
| :------: | :----------------------: |
|  always  |     每个写命令都同步     |
| everysec |       每秒同步一次       |
|    no    | 让操作系统来决定何时同步 |

- always 选项会严重减低服务器的性能；
- everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；
- no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。

随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

#### 6：分片

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0\~1000 的存储到实例 R0 中，用户 id 从 1001\~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。
- 服务器分片：Redis Cluster。



## 认证和会话管理

### JWT 和 session 区别

**Authentication和Authorization的区别：**

Authentication：用户认证，指的是验证用户的身份，例如你希望以小A的身份登录，那么应用程序需要通过用户名和密码确认你真的是小A。

Authorization：授权，指的是确认你的身份之后提供给你权限，例如用户小A可以修改数据，而用户小B只能阅读数据。

由于http协议是无状态的，每一次请求都无状态。当一个用户通过用户名和密码登录了之后，他的下一个请求不会携带任何状态，应用程序无法知道他的身份，那就必须重新认证。因此我们希望用户登录成功之后的每一次http请求，都能够保存他的登录状态。

目前主流的用户认证方法有基于token和基于session两种方式。

#### 基于session的用户认证

基于session的认证流程如下：

![img](https://img2018.cnblogs.com/blog/1500605/201812/1500605-20181208212640810-374114842.png)

 

```
1. 用户输入其登录信息
2. 服务器验证信息是否正确，并创建一个session，然后将其存储在数据库中
3. 服务器为用户生成一个sessionId，将具有sesssionId的Cookie将放置在用户浏览器中
4. 在后续请求中，会根据数据库验证sessionID，如果有效，则接受请求
5. 一旦用户注销应用程序，会话将在客户端和服务器端都被销毁
```

 

#### 基于token(令牌)的认证

最常用的是JSON Web Token（jwt）：

![img](https://img2018.cnblogs.com/blog/1500605/201812/1500605-20181208214418102-1938938567.png)

 

```
1. 用户输入其登录信息
2. 服务器验证信息是否正确，并返回已签名的token
3. token储在客户端，例如存在local storage或cookie中
4. 之后的HTTP请求都将token添加到请求头里
5. 服务器解码JWT，并且如果令牌有效，则接受请求
6. 一旦用户注销，令牌将在客户端被销毁，不需要与服务器进行交互一个关键是，令牌是无状态的。后端服务器不需要保存令牌或当前session的记录。
```

 

**jwt的组成**

#### jwt的认证原理：

一个jwt实际上就是一个字符串，它由三部分组成，**头部**、**载荷**与**签名**，这三个部分都是json格式。

**头部（Header）**

头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。

```
{
  "typ": "JWT",
  "alg": "HS256"
}
```

在这里，我们说明了这是一个JWT，并且我们所用的签名算法是HS256算法。

 

**载荷（Payload）**

载荷可以用来放一些不敏感的信息。

```
{
    "iss": "John Wu JWT",
    "iat": 1441593502,
    "exp": 1441594722,
    "aud": "www.example.com",
    "sub": "jrocket@example.com",
    "from_user": "B",
    "target_user": "A"
}
```

这里面的前五个字段都是由JWT的标准所定义的。

- `iss`: 该JWT的签发者
- `sub`: 该JWT所面向的用户
- `aud`: 接收该JWT的一方
- `exp`(expires): 什么时候过期，这里是一个Unix时间戳
- `iat`(issued at): 在什么时候签发的

把头部和载荷分别进行Base64编码之后得到两个字符串，然后再将这两个编码后的字符串用英文句号`.`连接在一起（头部在前），形成新的字符串：

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0
```

**签名（signature）**

最后，我们将上面拼接完的字符串用HS256算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。加密后的内容也是一个字符串，最后这个字符串就是签名，把这个签名拼接在刚才的字符串后面就能得到完整的jwt。header部分和payload部分如果被篡改，由于篡改者不知道密钥是什么，也无法生成新的signature部分，服务端也就无法通过，在jwt中，消息体是透明的，使用签名可以保证消息不被篡改。

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM
```

 

#### 区别和优缺点

基于session和基于jwt的方式的主要区别就是用户的状态保存的位置，session是保存在服务端的，而jwt是保存在客户端的。

 

**jwt的优点：**

1. 可扩展性好

应用程序分布式部署的情况下，session需要做多机数据共享，通常可以存在数据库或者redis里面。而jwt不需要。

2. 无状态

jwt不在服务端存储任何状态。RESTful API的原则之一是无状态，发出请求时，总会返回带有参数的响应，不会产生附加影响。用户的认证状态引入这种附加影响，这破坏了这一原则。另外jwt的载荷中可以存储一些常用信息，用于交换信息，有效地使用 JWT，可以降低服务器查询数据库的次数。

 

**jwt的缺点：**

1. 安全性

由于jwt的payload是使用base64编码的，并没有加密，因此jwt中不能存储敏感数据。而session的信息是存在服务端的，相对来说更安全。

2. 性能

jwt太长。由于是无状态使用JWT，所有的数据都被放到JWT里，如果还要进行一些数据交换，那载荷会更大，经过编码之后导致jwt非常长，cookie的限制大小一般是4k，cookie很可能放不下，所以jwt一般放在local storage里面。并且用户在系统中的每一次http请求都会把jwt携带在Header里面，http请求的Header可能比Body还要大。而sessionId只是很短的一个字符串，因此使用jwt的http请求比使用session的开销大得多。

3. 一次性

无状态是jwt的特点，但也导致了这个问题，jwt是一次性的。想修改里面的内容，就必须签发一个新的jwt。

（1）无法废弃

通过上面jwt的验证机制可以看出来，一旦签发一个jwt，在到期之前就会始终有效，无法中途废弃。例如你在payload中存储了一些信息，当信息需要更新时，则重新签发一个jwt，但是由于旧的jwt还没过期，拿着这个旧的jwt依旧可以登录，那登录后服务端从jwt中拿到的信息就是过时的。为了解决这个问题，我们就需要在服务端部署额外的逻辑，例如设置一个黑名单，一旦签发了新的jwt，那么旧的就加入黑名单（比如存到redis里面），避免被再次使用。

（2）续签

如果你使用jwt做会话管理，传统的cookie续签方案一般都是框架自带的，session有效期30分钟，30分钟内如果有访问，有效期被刷新至30分钟。一样的道理，要改变jwt的有效时间，就要签发新的jwt。最简单的一种方式是每次请求刷新jwt，即每个http请求都返回一个新的jwt。这个方法不仅暴力不优雅，而且每次请求都要做jwt的加密解密，会带来性能问题。另一种方法是在redis中单独为每个jwt设置过期时间，每次访问时刷新jwt的过期时间。

 

可以看出想要破解jwt一次性的特性，就需要在服务端存储jwt的状态。但是引入 redis 之后，就把无状态的jwt硬生生变成了有状态了，违背了jwt的初衷。而且这个方案和session都差不多了。

 

**总结**

适合使用jwt的场景：

- 有效期短
- 只希望被使用一次

比如，用户注册后发一封邮件让其激活账户，通常邮件中需要有一个链接，这个链接需要具备以下的特性：能够标识用户，该链接具有时效性（通常只允许几小时之内激活），不能被篡改以激活其他可能的账户，一次性的。这种场景就适合使用jwt。

而由于jwt具有一次性的特性。单点登录和会话管理非常不适合用jwt，如果在服务端部署额外的逻辑存储jwt的状态，那还不如使用session。基于session有很多成熟的框架可以开箱即用，但是用jwt还要自己实现逻辑。

 





### SSO (Single sign-on)

通常公司内部会有非常多的平台供大家使用，比如人力资源，代码管理，日志监控，预算申请等等。如果每一个平台都实现自己的用户体系的话无疑是巨大的浪费，所以公司内部会有一套 **公用的用户体系**，用户只要登陆之后，就能够 **访问所有的系统**。这就是 **单点登录**。

`SSO` 是一类 **解决方案** 的统称，而在具体的实施方面，我们有两种策略可供选择：

- **SAML 2.0**
- **OAuth 2.0**

接下来我们区别这 **两种授权方式** 有什么不同。但是在描述 **不同的策略** 之前，我们先叙述几个 **共有的特性**，并且相当重要的概念。

**Authentication VS Authorisation**

- **Authentication:** 身份鉴别，以下简称 **认证**；
- **Authorisation:** 资源访问 **授权**。

**认证** 的作用在于 **认可** 你能够访问系统，用于 **鉴别访问者** 是否是 **合法用户**；而 **授权** 用于决定你有访问 **哪些资源的权限**。

大多数人不会区分这两者的区别，因为站在用户的立场上。而作为系统的设计者来说，这两者是有差别的，这是不同的两个工作职责。我们可以只需要 **认证功能**，而不需要 **授权功能**，甚至不需要自己实现 **认证功能**。而借助 `Google` 的认证系统，即用户可以用 `Google` 的账号进行登陆。

**Authorization Server/Identity Provider(IdP)**

把负责 **认证的服务** 称为 `AuthorizationServer` 或者 `IdentityProvider`，以下简称 `IDP`。

**Service Provider(SP)/Resource Server**

把负责 **提供资源**（`API` 调用）的服务称为 `ResourceServer` 或者 `ServiceProvider`，以下简称 `SP`。

### **SAML 2.0**

1. 还 **未登陆** 的用户 **打开浏览器** 访问你的网站（`SP`），网站 **提供服务** 但是并 **不负责用户认证**。
2. 于是 `SP` 向 `IDP` 发送了一个 `SAML` 认证请求，同时 `SP` 将 **用户浏览器** 重定向到 `IDP`。
3. `IDP` 在验证完来自 `SP` 的 **请求无误** 之后，在浏览器中呈现 **登陆表单** 让用户填写 **用户名** 和 **密码** 进行登陆。
4. 一旦用户登陆成功， `IDP` 会生成一个包含 **用户信息**（**用户名** 或者 **密码**）的 `SAML token`（`SAML token` 又称为 `SAML Assertion`，本质上是 `XML` 节点）。`IDP` 向 `SP` 返回 `token`，并且将 **用户重定向** 到 `SP` (`token` 的返回是在 **重定向步骤** 中实现的，下面会详细说明)。
5. `SP` 对拿到的 `token` 进行验证，并从中解析出 **用户信息**，例如 **用户是谁** 以及 **用户的权限** 有哪些。此时就能够根据这些信息允许用户访问我们网站的内容。

当用户在 `IDP` 登陆成功之后，`IDP` 需要将用户 **再次重定向** 到 `SP` 站点，这一步通常有两个办法：

- `HTTP` 重定向：这并不推荐，因为 **重定向** 的 `URL` 长度 **有限制**，无法携带更长的信息，比如 `SAML Token`。
- `HTTP POST` 请求：这个是更常规的做法，当用户登陆完毕之后渲染出一个表单，用户点击后向 `SP` 提交 `POST` 请求。又或者可以使用 `JavaScript` 向 `SP` 发出一个 `POST` 请求。

如果你的应用是基于 `Web`，那么以上的方案没有任何问题。但如果你开发的是一个 `iOS` 或者 `Android` 的手机应用，那么问题就来了：

1. 用户在 `iPhone` 上打开应用，此时用户需要通过 `IDP` 进行认证。
2. 应用跳转至 `Safari` 浏览器，在登陆认证完毕之后，需要通过 `HTTP POST` 的形式将 `token` 返回至 **手机应用**。

虽然 `POST` 的 `url` 可以 **拉起应用**，但是 **手机应用** 无法解析 `POST` 的内容，我们也就无法读取 `SAML Token`。

> 当然还是有办法的，比如在 `IDP` **授权阶段** 不跳转至系统的 `Safari` 浏览器，在 **内嵌** 的 `Webview` 中解决，在想方设法从 `Webview` 中提取 `token`，或者利用 **代理服务器**。

无论如何，`SAML 2.0` 并 **不适用** 于当下 **跨平台** 的场景，这也许与它产生的年代也有关系，它诞生于 `2005` 年，在那个时刻 `HTTP POST` 确实是最好的选择方案。

### OAuth 2.0

我们先简单了解 `SSO` 下的 `OAuth2.0` 的流程。

1. 用户通过 **客户端**（可以是 **浏览器** 也可以是 **手机应用**）想要访问 `SP` 上的资源，但是 `SP` 告诉用户需要进行 **认证**，将用户 **重定向** 至 `IDP`。
2. `IDP` 向 **用户** 询问 `SP` 是否可以访问 **用户信息**。如果用户同意，`IDP` 向 **客户端** 返回 `authorization code`。
3. 客户端拿到 `authorization code` 向 `IDP` 交换 `access token`，并拿着 `access token` 向 `SP` 请求资源。
4. `SP` 接受到请求之后，拿着附带的 `token` 向 `IDP` 验证 **用户的身份**。确认身份无误后，`SP` 向 **客户端** 发放相关资源。

那么 `OAuth` 是如何避免 `SAML` 流程下 **无法解析** `POST` 内容的信息的呢？

- 一方面是用户从 `IDP` 返回 **客户端** 的方式，也是通过 `URL` 重定向，这里的 `URL` 允许 **自定义** `schema`，所以即使在 **手机** 上也能 **拉起应用**；
- 另一方面因为 `IDP` 向 **客户端** 传递的是 `authorization code`，而不是 `XML` 信息，所以 `code` 可以很轻易的附着在 **重定向** `URL` 上进行传递。

但以上的 `SSO` 流程体现不出 `OAuth` 的本意。`OAuth` 的本意是 **一个应用** 允许 **另一个应用** 在 **用户授权** 的情况下 **访问自己的数据**。

`OAuth` 的设计本意更倾向于 **授权而非认证**（当然授权用户信息就间接实现了认证），虽然 `Google` 的 `OAuth 2.0 API` 同时支持 **授权** 和 **认证**。所以你在使用 `Facebook` 或者 `Gmail` 账号登陆第三方站点时，会出现 **授权对话框**，告诉你 **第三方站点** 可以访问你的哪些信息，需要征得你的同意。

在上面 `SSO` 的 `OAuth` 流程中涉及三方角色: `SP`, `IDP` 以及 `Client`。但在实际工作中 `Client` 可以是不存在的，例如你编写了一个 **后端程序** 定时的通过 `Google API` 从 `Youtube` 拉取最新的节目数据，那么你的 **后端程序** 需要得到 `Youtube` 的 `OAuth` **授权** 即可。

### OAuth VS OpenId

如果你有留心的话，你会在某些站点看到允许以 `OpenID` 的方式登陆，其实也就是以 `Facebook` 账号或者 `Google` 账号登陆站点：

`OpenID` 和 `OAuth` 很像。但本质上来说它们是截然不同的两个东西：

- **OpenID:** 只用于 **身份认证**（`Authentication`），允许你以 **同一个账户** 在 **多个网站登陆**。它仅仅是为你的 **合法身份** 背书，当你以 `Facebook` 账号登陆某个站点之后，该站点 **无权访问** 你的在 `Facebook` 上的 **数据**。
- **OAuth:** 用于 **授权**（`Authorisation`），允许 **被授权方** 访问 **授权方** 的 **用户数据**。

### Refresh Token 和 access token

现在可以回答上面的问题了，为什么我们需要 `refresh token`？

这样的处理是为了 **职责的分离**：

- **refresh token:** 负责 **身份认证**；
- **access token:** 负责 **请求资源**。

虽然 `refresh token` 和 `access token` 都由 `IDP` 发出，但是 `access token` 还要和 `SP` 进行 **数据交换**，如果 **公用的话** 这样就会有 **身份泄露** 的可能。并且 `IDP` 和 `SP` 可能是 **完全不同** 的 **服务提供** 的。而在上文，我们之所以没有这样的顾虑是因为 `IDP` 和 `SP` 都是 `Google`。

### spring session

#### 一、为什么要spring-session

在传统单机web应用中，一般使用tomcat/jetty等web容器时，用户的session都是由容器管理。浏览器使用cookie中记录sessionId，容器根据sessionId判断用户是否存在会话session。这里的限制是，session存储在web容器中，被单台服务器容器管理。

但是网站主键演变，分布式应用和集群是趋势（提高性能）。此时用户的请求可能被负载分发至不同的服务器，此时传统的web容器管理用户会话session的方式即行不通。除非集群或者分布式web应用能够共享session，尽管tomcat等支持这样做。但是这样存在以下两点问题：

- 需要侵入web容器，提高问题的复杂
- web容器之间共享session，集群机器之间势必要交互耦合

基于这些，必须提供新的可靠的集群分布式/集群session的解决方案，突破traditional-session单机限制（即web容器session方式，下面简称traditional-session），spring-session应用而生。

#### 二、比较traditional-session方案和spring-session方案

下图展示了traditional-session和spring-session的区别

![img](https://img2018.cnblogs.com/blog/1286175/201809/1286175-20180918232306231-326643336.png)

传统模式中，当request进入web容器，根据reqest获取session时，如果web容器中存在session则返回，如果不存在，web容器则创建一个session。然后返回response时，将sessonId作为response的head一并返回给客户端或者浏览器。

但是上节中说明了traditional-session的局限性在于：单机session。在此限制的相反面，即将session从web容器中抽出来，形成独立的模块，以便分布式应用或者集群都能共享，即能解决。

spring-session的核心思想在于此：将session从web容器中剥离，存储在独立的存储服务器中。目前支持多种形式的session存储器：Redis、Database、MogonDB等。session的管理责任委托给spring-session承担。当request进入web容器，根据request获取session时，由spring-session负责存存储器中获取session，如果存在则返回，如果不存在则创建并持久化至存储器中。

#### 三、JSR340规范与spring-session的透明继承

JSR340是Java Servlet 3.1的规范提案，其中定义了大量的api，包括：servlet、servletRequest/HttpServletRequest/HttpServletRequestWrapper、servletResponse/HttpServletResponse/HttpServletResponseWrapper、Filter、Session等，是标准的web容器需要遵循的规约，如tomcat/jetty/weblogic等等。

在日常的应用开发中，develpers也在频繁的使用servlet-api，比如：

以下的方式获取请求的session：

```
HttpServletRequest request = ...
HttpSession session = request.getSession(false);
```

其中HttpServletRequest和HttpSession都是servlet规范中定义的接口，web容器实现的标准。那如果引入spring-session，要如何获取session？

- 遵循servlet规范，同样方式获取session，对应用代码无侵入且对于developers透明化
- 全新实现一套session规范，定义一套新的api和session管理机制

两种方案都可以实现，但是显然第一种更友好，且具有兼容性。spring-session正是第一种方案的实现。

实现第一种方案的关键点在于做到透明和兼容

- 接口适配：仍然使用HttpServletRequest获取session，获取到的session仍然是HttpSession类型——**适配器模式**
- 类型包装增强：Session不能存储在web容器内，要外化存储——**装饰模式**

让人兴奋的是，以上的需求在Servlet规范中的扩展性都是予以支持！Servlet规范中定义一系列的接口都是支持扩展，同时提供Filter支撑扩展点。建议阅读《JavaTM Servlet Specification》。

热脑活动结束，下面章节正式进入今天的主题：**spring-session揭秘**

#### 四、Spring Session 探索

主要从以下两个方面来说spring-session：

- 特点
- 工作原理

**一.特点**

spring-session在无需绑定web容器的情况下提供对集群session的支持。并提供对以下情况的透明集成：

- HttpSession：容许替换web容器的HttpSession
- WebSocket：使用WebSocket通信时，提供Session的活跃
- WebSession：容许以应用中立的方式替换webflux的webSession

**二.工作原理**

再详细阅读源码之前先来看张图，介绍下spring-session中的核心模块以及之间的交互。

![img](https://img2018.cnblogs.com/blog/1286175/201809/1286175-20180918232339701-1747137442.png)

spring-session分为以下核心模块：

- SessionRepositoryFilter：Servlet规范中Filter的实现，用来切换HttpSession至Spring Session，包装HttpServletRequest和HttpServletResponse
- HttpServerletRequest/HttpServletResponse/HttpSessionWrapper包装器：包装原有的HttpServletRequest、HttpServletResponse和Spring Session，实现切换Session和透明继承HttpSession的关键之所在
- Session：Spring Session模块
- SessionRepository：管理Spring Session的模块
- HttpSessionStrategy：映射HttpRequst和HttpResponse到Session的策略

#### 五、spring session 提供功能

**特征**

Spring Session使支持集群会话变得很简单，而不必依赖于特定于应用程序容器的解决方案。它还提供了透明的集成：

- `HttpSession` -允许以应用程序容器（即Tomcat）中立的方式替换HttpSession，并支持在标头中提供会话ID以与RESTful API一起使用
- `WebSocket` -提供了在接收WebSocket消息时保持HttpSession存活的功能
- `WebSession` -允许以与应用程序容器无关的方式替换Spring WebFlux的WebSession

**模块**

Spring Session由以下模块组成：

- Spring Session Core-提供核心的Spring Session功能和API
- Spring Session Data Redis-提供由Redis支持的SessionRepository和ReactiveSessionRepository实现以及配置支持
- Spring Session JDBC-提供由关系数据库支持的SessionRepository实现和配置支持
- Spring Session Hazelcast-提供由Hazelcast支持的SessionRepository实现和配置支持

**功能**

会话超时、session共享、一个账号只能同时在线一个、集群session

### spring security

**Spring Security 模块**

- **核心模块** - spring-security-core.jar：包含核心验证和访问控制类和接口，远程支持的基本配置API，是基本模块
- **远程调用** - spring-security-remoting.jar：提供与 Spring Remoting 集成
- **网页** - spring-security-web.jar：包括网站安全的模块，提供网站认证服务和基于URL访问控制
- **配置** - spring-security-config.jar：包含安全命令空间解析代码，若使用XML进行配置则需要
- **LDAP** - spring-security-ldap.jar：LDAP 验证和配置，若需要LDAP验证和管理LDAP用户实体
- **ACL访问控制表** - spring-security-acl.jar：ACL专门领域对象的实现
- **CAS** - spring-security-cas.jar：CAS客户端继承，若想用CAS的SSO服务器网页验证
- **OpenID** - spring-security-openid.jar：OpenID网页验证支持
- **Test** - spring-security-test.jar：支持Spring Security的测试

**会话管理**

**Spring Security**提供的会话并发控制是基于内存实现的，在集群部署时如果想要使用会话并发控制，则必须进行适配。 session共享，本质上就是存储容器的变动，但如何得到最优存取结构、如何准确清理过期会话，以及如何整合**WebSocket**等无法回避。**Spring Session**就是专门用于解决集群会话问题的，它不仅为集群会话提供了非常完善的支持，与**Spring Security**的整合也有专门的实现。 **Spring Session**支持多种类型的存储容器，包括**Redis**、**MongoDB**等。由于接下来的整合都是基于**Redis**的，所以大家可以自行准备**Redis**测试环境，具体如何安装不再赘述。

**登录支持**

支持oauth2的四种授权模式登录、用户名密码加图形验证码登录、手机号加密码登录、openId登录、第三方系统单点登录（扫码登录、人脸登录、指纹登录、虹膜登录）

**CAS、LDAP、OAuth**

今天介绍的几种单点登录系统，均具有较高的安全性，都能较好地完成单点登录系统的需求。

- OAuth协议能广泛应用于互联网中，基于大企业的巨大用户量，能减少小网站的注册推广成本，并且能做到更加便捷的资源共享。
- LDAP协议适用于企业用户使用，通过LDAP协议，能较好地管理员工在公司各系统之间的授权与访问。
- CAS模型，作为权威机构开发的系统，具有很好的兼容性与安全性，广泛应用于各大高校等大型组织，能很好地完成大量系统的对接与大量人员的使用。



## 注册中心



|                 | **Nacos**                  | **Eureka**  | **Consul**        | **Zookeeper** |
| :-------------- | :------------------------- | :---------- | :---------------- | :------------ |
| 一致性协议      | CP+AP                      | AP          | CP                | CP            |
| 健康检查        | TCP/HTTP/MYSQL/Client Beat | Client Beat | TCP/HTTP/gRPC/Cmd | Keep Alive    |
| 负载均衡策略    | 权重/ metadata/Selector    | Ribbon      | Fabio             | —             |
| 雪崩保护        | 有                         | 有          | 无                | 无            |
| 自动注销实例    | 支持                       | 支持        | 支持              | 支持          |
| 访问协议        | HTTP/DNS                   | HTTP        | HTTP/DNS          | TCP           |
| 监听支持        | 支持                       | 支持        | 支持              | 支持          |
| 多数据中心      | 支持                       | 支持        | 支持              | 不支持        |
| 跨注册中心同步  | 支持                       | 不支持      | 支持              | 不支持        |
| SpringCloud集成 | 支持                       | 支持        | 支持              | 支持          |
| Dubbo集成       | 支持                       | 不支持      | 支持              | 支持          |
| K8S集成         | 支持                       | 不支持      | 支持              | 不支持        |





## 数据库整理

### 1：事务

**1. 原子性（Atomicity）**

事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。

回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

**2. 一致性（Consistency）**

数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。在原子性和隔离性的基础上保证一致性。

**3. 隔离性（Isolation）**

一个事务所做的修改在最终提交以前，对其它事务是不可见的。

**4. 持久性（Durability）**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

系统发生奔溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。

**四、隔离级别**

**未提交读（READ UNCOMMITTED）**

事务中的修改，即使没有提交，对其它事务也是可见的。

**提交读（READ COMMITTED）**

一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。

**可重复读（REPEATABLE READ）**

保证在同一个事务中多次读取同一数据的结果是一样的。

**可串行化（SERIALIZABLE）**

强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。

该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。

----

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207223400787.png"/> </div><br>

### 2：索引

#### 单列索引 与 复合索引

只包含一个字段的索引叫做单列索引，包含两个或以上字段的索引叫做复合索引（或组合索引）。建立复合索引时，字段的顺序极其重要。

下面这个SQL语句在 列X，列Y，列Z 上建立了一个复合索引。

```mysql
CREATE INDEX 索引名 ON 表名(列名X, 列名Y, 列名Z);
```

其实这相当于建立了三个索引，分别是：

1、单列索引（列X） 2、复合索引（列X, 列Y） 3、复合索引（列X，列Y，列Z）。

#### 唯一索引 与 主键

唯一索引是在表上一个或者多个字段组合建立的索引，这个（或这几个）字段的值组合起来在表中不可以重复。一张表可以建立任意多个唯一索引，但一般只建立一个。

主键是一种特殊的唯一索引，区别在于，唯一索引列允许null值，而主键列不允许为null值。一张表最多建立一个主键，也可以不建立主键。

#### 聚簇索引、非聚簇索引、主键

在《数据库原理》一书中是这么解释聚簇索引和非聚簇索引的区别的：

聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。

怎么理解呢？

聚簇索引的顺序，就是数据在硬盘上的物理顺序。一般情况下主键就是默认的聚簇索引。

一张表只允许存在一个聚簇索引，因为真实数据的物理顺序只能有一种。如果一张表上还没有聚簇索引，为它新创建聚簇索引时，就需要对已有数据重新进行排序，所以对表进行修改速度较慢是聚簇索引的缺点，对于经常更新的列不宜建立聚簇索引。

聚簇索引性能最好，因为一旦具有第一个索引值的记录被找到，具有连续索引值的记录也一定物理地紧跟其后。一张表只能有一个聚簇索引，所以非常珍贵，必须慎重设置，一般要根据这个表最常用的SQL查询方式选择某个（或多个）字段作为聚簇索引（或复合聚簇索引）。

聚簇索引默认是主键，如果表中没有定义主键，InnoDB[[1\]](https://zhuanlan.zhihu.com/p/66553466?utm_source=wechat_session&utm_medium=social&utm_oi=861319674003066880#ref_77889_1)会选择一个唯一的非空索引代替（“唯一的非空索引”是指列不能出现null值的唯一索引，跟主键性质一样）。如果没有这样的索引，InnoDB会隐式地定义一个主键来作为聚簇索引。

#### 聚簇索引 与 唯一索引

严格来说，聚簇索引不一定是唯一索引，聚簇索引的索引值并不要求是唯一的，唯一聚簇索引才是！在一个有聚簇索引的列上是可以插入两个或多个相同值的，这些相同值在硬盘上的物理排序与聚簇索引的排序相同，仅此而已。

#### 聚簇索引与非聚簇索引（也叫二级索引）

**聚簇索引**：也叫主索引，一级索引，一个表只能有一个聚簇索引，主索引的叶子节点 data 域记录着完整的数据记录。

**非聚簇索引**：也叫辅助索引，二级索引，辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

**通俗点讲**

- 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
- 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因

澄清一个概念：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值

**聚簇索引默认是主键**，如果表中没有定义主键，InnoDB 会选择一个**唯一的非空索引**代替。如果没有这样的索引，InnoDB 会**隐式定义一个主键**来作为聚簇索引。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。**如果你已经设置了主键为聚簇索引，必须先删除主键，然后添加我们想要的聚簇索引，最后恢复设置主键即可**。

**聚簇索引的优势**

看上去聚簇索引的效率明显要低于非聚簇索引，因为**每次使用辅助索引检索都要经过两次B+树查找**，这不是多此一举吗？聚簇索引的优势在哪？

1. 由于**行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问**，不必访问磁盘。这样**主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回**了，**如果按照主键Id来组织数据，获得数据更快**。
2. **辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处**是，**减少了当出现行移动或者数据页分裂时辅助索引的维护工作**，**使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"**。**也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响**。
3. 聚簇索引适合用在排序的场合，非聚簇索引不适合
4. 取出一定范围数据的时候，使用用聚簇索引
5. 二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据
6. 可以把**相关数据保存在一起**。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。

#### 组合索引

组合索引又叫多列索引，复合索引。

**为什么不对每一列创建索引**

- 减少开销
- 覆盖索引
- 效率高

减少开销：假如对col1、col2、col3创建组合索引，相当于创建了（col1）、（col1，col2）、（col1，col2，col3）3个索引

覆盖索引：假如查询SELECT col1, col2, col3 FROM 表名，由于查询的字段存在索引页中，那么可以从索引中直接获取，而不需要回表查询

效率高：对col1、col2、col3三列分别创建索引，MySQL只会选择辨识度高的一列作为索引。假设有100w的数据，一个索引筛选出10%的数据，那么可以筛选出10w的数据；对于组合索引而言，可以筛选出100w*10%*10%*10%=1000条数据

**最左匹配原则**

假设我们创建（col1，col2，col3）这样的一个组合索引，那么相当于对col1列进行排序，也就是我们创建组合索引，以最左边的为准，只要查询条件中带有最左边的列，那么查询就会使用到索引

#### 索引分类

**存储方式区分**

B+Tree 索引、哈希索引、全文索引、空间数据索引

**逻辑区分**

- 普通索引：仅加速查询
- 唯一索引：加速查询 + 列值唯一（可以有null）
- 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个
- 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并
- 全文索引：对文本的内容进行分词，进行搜索





### 3：数据库优化

#### 3.1、索引优化

**1. 独立的列**

在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。

例如下面的查询不能使用 actor_id 列的索引：

```sql
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
```

**2. 多列索引**

在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。

```sql
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

**3. 索引列的顺序**

让选择性最强的索引列放在前面。

索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。

例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。

```sql
SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,
COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,
COUNT(*)
FROM payment;
```

```html
   staff_id_selectivity: 0.0001
customer_id_selectivity: 0.0373
               COUNT(*): 16049
```

**4. 前缀索引**

对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。

前缀长度的选取需要根据索引选择性来确定。

**5. 覆盖索引**

索引包含所有需要查询的字段的值。

具有以下优点：

- 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
- 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
- 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

**索引的优点**

- 大大减少了服务器需要扫描的数据行数。

- 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。

- 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

**索引的使用条件**

- 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；

- 对于中到大型的表，索引就非常有效；

- 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

#### 3.2、查询优化

**3.2.1 使用 Explain 进行分析**

Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有：

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

**3.2.2 优化数据访问**

**1. 减少请求的数据量**

- 只返回必要的列：最好不要使用 SELECT * 语句。
- 只返回必要的行：使用 LIMIT 语句来限制返回的数据。
- 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。

**2. 减少服务器端扫描的行数**

最有效的方式是使用索引来覆盖查询。

**3.2.3 重构查询方式**

**1. 切分大查询**

一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

```sql
DELETE FROM messages WHERE create < DATE_SUB(NOW(), INTERVAL 3 MONTH);
```

```sql
rows_affected = 0
do {
    rows_affected = do_query(
    "DELETE FROM messages WHERE create  < DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")
} while rows_affected > 0
```

**2. 分解大连接查询**

将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：

- 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
- 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
- 减少锁竞争；
- 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
- 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。

```sql
SELECT * FROM tag
JOIN tag_post ON tag_post.tag_id=tag.id
JOIN post ON tag_post.post_id=post.id
WHERE tag.tag='mysql';
```

```sql
SELECT * FROM tag WHERE tag='mysql';
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
```

#### 3.3、复制

主从复制、读写分离

#### 3.4、切分

分库分表：水平切分、垂直切分

**Sharding 策略**

- 哈希取模：hash(key) % N；
- 范围：可以是 ID 范围也可以是时间范围；
- 映射表：使用单独的一个数据库来存储映射关系。

**Sharding 存在的问题**

**1. 事务问题**

使用分布式事务来解决，比如 XA 接口。

**2. 连接**

可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。

**3. ID 唯一性**

- 使用全局唯一 ID（GUID）
- 为每个分片指定一个 ID 范围
- 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)



## 各种锁的简介

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/7f749fc8.png)

锁消除、锁粗化、读写锁

## 进程、线程、协程

**进程与线程的区别**

线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。

**根本区别**：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位

**资源开销**：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

**包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

**内存分配**：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的

**影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

**执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

**协程与线程的区别**

1) 一个线程可以多个协程，一个进程也可以单独拥有多个协程。

2) 线程进程都是同步机制，而协程则是异步。

3) 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。

4）线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。

5）协程并不是取代线程, 而且抽象于线程之上, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程。

6）线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。

**Netty**

Netty是一款基于NIO（Nonblocking I/O，非阻塞IO）开发的网络通信框架，对比于BIO（Blocking I/O，阻塞IO），他的并发性能得到了很大提高

从这两图可以看出，NIO的单线程能处理连接的数量比BIO要高出很多，而为什么单线程能处理更多的连接呢？原因就是图二中出现的`Selector`。
 当一个连接建立之后，他有两个步骤要做，第一步是接收完客户端发过来的全部数据，第二步是服务端处理完请求业务之后返回response给客户端。NIO和BIO的区别主要是在第一步。
 在BIO中，等待客户端发数据这个过程是阻塞的，这样就造成了一个线程只能处理一个请求的情况，而机器能支持的最大线程数是有限的，这就是为什么BIO不能支持高并发的原因。
 而NIO中，当一个Socket建立好之后，Thread并不会阻塞去接受这个Socket，而是将这个请求交给Selector，Selector会不断的去遍历所有的Socket，一旦有一个Socket建立完成，他会通知Thread，然后Thread处理完数据再返回给客户端——**这个过程是不阻塞的**，这样就能让一个Thread处理更多的请求了。

**Netty为什么传输快**

Netty的传输快其实也是依赖了NIO的一个特性——*零拷贝*。我们知道，Java的内存有堆内存、栈内存和字符串常量池等等，其中堆内存是占用内存空间最大的一块，也是Java对象存放的地方，一般我们的数据如果需要从IO读取到堆内存，中间需要经过Socket缓冲区，也就是说一个数据会被拷贝两次才能到达他的的终点，如果数据量大，就会造成不必要的资源浪费。
 Netty针对这种情况，使用了NIO中的另一大特性——零拷贝，当他需要接收数据的时候，他会在堆内存之外开辟一块内存，数据就直接从IO读到了那块内存中去，在netty里面通过ByteBuf可以直接对这些数据进行直接操作，从而加快了传输速度。

NIO

 **能解决什么问题？**

   为什么要有NIO，NIO是什么？

首先看一下BIO，如果有一台服务器，能承受简单的客户端请求，那么使用io和net中的同步、阻塞式API应该是可以实现了。但是为了一个用户的请求而单独启动一个线程，开销应该不小吧。java语言对线程的实现是比较重量的，启动或销毁线程，都会有明显开销，每个线程都有单独的线程棧占用明显的内存。引入线程池，就能很大程度的避免不必要的开销。

![img](https://img-blog.csdn.net/20180927091820246?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhMDA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

这种情况适合连接数并不多，只有最多几百个连接的普通应用，能比较好的进行工作，但如果连接数量剧增，这种实现方式就无法很好的工作了，对于并发量要求较高的企业，这种方案，肯定是不可取的。

NIO采用的是一种多路复用的机制，利用单线程轮询事件，高效定位就绪的Channel来决定做什么，只是Select阶段是阻塞式的，能有效避免大量连接数时，频繁线程的切换带来的性能或各种问题。

![img](https://img-blog.csdn.net/20180927094928997?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhMDA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

 

上图随便画的，只是方便理解，并不能作为实现的具体的参考。

首先，Requester方通过Selector.open()创建了一个Selector准备好了调度角色。

创建了SocketChannel(ServerSocketChannel) 并注册到Selector中，通过设置key（SelectionKey）告诉调度者所应该关注的连接请求。

阻塞，Selector阻塞在select操作中，如果发现有Channel发生连接请求，就会唤醒处理请求。

**NIO同步非阻塞式IO**

   对比BIO的同步阻塞IO操作，实际上NIO是同步非阻塞IO，一个线程在同步的进行轮询检查，Selector不断轮询注册在其上的Channel，某个Channel上面发生读写连接请求，这个Channel就处于就绪状态，被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。

​    同步和异步说的是消息的通知机制，这个线程仍然要定时的读取stream，判断数据有没有准备好，client采用循环的方式去读取（线程自己去抓去信息），CPU被浪费。

   非阻塞：体现在，这个线程可以去干别的，不需要一直在这等着。Selector可以同时轮询多个Channel，因为JDK使用了epoll()代替传统的select实现，没有最大连接句柄限制。所以只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端。

**AIO**

是在NIO的基础上引入异步通道的概念，实现异步非阻塞式的IO处理。如下图（网络截图）：

![img](https://img-blog.csdn.net/20180927103917548?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhMDA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

​    AIO不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写。什么意思呢？NIO采用轮询的方式，一直在轮询的询问stream中数据是否准备就绪，如果准备就绪发起处理。但是AIO就不需要了，AIO框架在windows下使用windows IOCP技术，在Linux下使用epoll多路复用IO技术模拟异步IO， 即：应用程序向操作系统注册IO监听，然后继续做自己的事情。操作系统发生IO事件，并且准备好数据后，在主动通知应用程序，触发相应的函数（这就是一种以订阅者模式进行的改造）。由于应用程序不是“轮询”方式而是订阅-通知方式，所以不再需要selector轮询，由channel通道直接到操作系统注册监听。

**NIO（AIO）中几个概念**

**缓冲区 Buffer**

 NIO基于块进行数据处理，在NIO中所有数据的读取都是通过缓冲Buffer进行处理。

   具体的缓存区有这些：ByteBuffe、CharBuffer、 ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。他们实现了相同的接口：Buffer。

**通道 Channel**

   对数据的读取和写入要通过Channel通道。通道不同于流的地方就是通道是双向的，用于读、写和同时读写操作。底层的操作系统的通道一般都是全双工的，全双工的Channel比流能更好的映射底层操作系统的API。

**多路复用器 Selector**

Selector提供选择已经就绪的任务的能力：

   Selector轮询注册在其上的Channel，如果某个Channel发生读写请求并且Channel就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。（同步）

   一个Selector可以同时轮询多个Channel，因为JDK使用了epoll()代替传统的select实现，所以没有最大连接句柄1024/2048的限制。所以，只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端。（非阻塞）

**NIO和AIO**

NIO：会等数据准备好后，再交由应用进行处理，数据的读取/写入过程依然在应用线程中完成，只是将等待的时间剥离到单独的线程中去，节省了数据准备时间，因为多路复用机制，Selector会得到复用，对于那些读写过程时间长的，NIO就不太适合。

AIO：读完（内核内存拷贝到用户内存）了系统再通知应用，使用回调函数，进行业务处理，AIO能够胜任那些重量级，读写过程长的任务。

 

 

**在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。**

下表总结了Java NIO和IO之间的主要差别，我会更详细地描述表中每部分的差异。

```
IO                NIO
面向流            面向缓冲
阻塞IO            非阻塞IO
无                选择器
```



actor、akka

epoll、多路复用、零拷贝、redis

IO设计模式：Reactor和Proactor对比



1、linux进程有4GB地址空间，如图所示：

![img](https://img-blog.csdn.net/20180721092710523?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5ODIzNjI3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

3G-4G大部分是共享的，是内核态的地址空间。这里存放整个内核的代码和所有的内核模块以及内核所维护的数据。

2、特权级的概念：

对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如分配物理内存，父子进程拷贝信息，拷贝设置页目录页表等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。最关键的工作必须交给特权级最高的进程去执行，这样可以做到集中管理，减少有限资源的访问和使用冲突。inter x86架构的cpu一共有四个级别，0-3级，0级特权级最高，3级特权级最低。

3、用户态和内核态的概念：

当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为3级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3状态不能访问Ring0的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为0级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。

用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须通过write、send等系统调用，这些系统调用会调用内核的代码。进程会切换到Ring0，然后进入3G-4G中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。

4、用户态和内核态的切换

当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。

用户态切换到内核态的3种方式

（1）系统调用

这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如fork（）就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如Linux的int 80h中断。

（2）异常

当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。

（3）外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤有事一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。

5、用户态到内核态具体的切换步骤：

（1）从当前进程的描述符中提取其内核栈的ss0及esp0信息。

（2）使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。

（3）将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。

**总线**

按总线的功能(传递信息的内容)分类，计算机中有三种类型的总线，即传送数据信息的数据总线、传送地址信息的地址总线和传送各种控制信息的控制总线。

1.数据总线
数据总线是CPU与存储器、CPU与I/O接口设备之间传送数据信息(各种指令数据信息)的总线，这些信号通过数据总线往返于CPU与存储器、CPU与I/O接口设备之间，因此，数据总线上的信息是双向传输的。

2.地址总线
地址总线上传送的是CPU向存储器、I/O接口设备发出的地址信息，寻址能力是CPU特有的功能，地址总线上传送的地址信息仅由CPU发出，因此，地址总线上的信息是单向传输的。

3.控制总线
控制总线传送的是各种控制信号，有CPU至存储器、I/O接口设备的控制信号，有I/O接口送向CPU的应答信号、请求信号，因此，控制总线是上的信息是双向传输的。控制信号包括时序信号、状态信号和命令信号(如读写信号、忙信号、中断信号)等。

例如向内存中写入数据是通过内存总线(包括数据总线、地址总线和控制总线)进行的，数据信息需通过数据总线传递至内存中，具体将这些数据信息写入内存的哪些单元则必须向地址总线传送地址信息确定，而哪个时刻开始向内存中写入数据则由控制总线获得的控制信号决定。

**I/O 模型**

一个输入操作通常包括两个阶段：

- 等待数据准备好
- 从内核向进程复制数据

对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。

Unix 有五种 I/O 模型：

- 阻塞式 I/O
- 非阻塞式 I/O
- I/O 复用（select 和 poll）
- 信号驱动式 I/O（SIGIO）
- 异步 I/O（AIO）

select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。



**零拷贝**

零拷贝技术的目标可以概括如下：

1. **避免数据拷贝**
    ①避免操作系统内核缓冲区之间进行数据拷贝操作。
    ②避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。
    ③用户应用程序可以避开操作系统直接访问硬件存储。
    ④数据传输尽量让 DMA 来做。
2. **综合目标**
    ①避免不必要的系统调用和上下文切换。
    ②需要拷贝的数据可以先被缓存起来。
    ③对数据进行处理尽量让硬件来做。



## 数据结构与容器

**1：数据结构层面**

逻辑结构（线性和非线性）、物理结构（顺序存储、链式存储、索引存储、散列存储）

**2：动态扩容层面**

初始大小、加载因子、扩容增量

| **Class** | **初始大小** | **加载因子** | **扩容倍数** | **底层实现**        | **是否线程安全** | **同步方式** |
| --------- | ------------ | ------------ | ------------ | ------------------- | ---------------- | ------------ |
| ArrayList | 10           | 1            | 1.5倍        | Object数组          | 否               |              |
| Vector    | 10           | 1            | 2倍          | Object数组          | 是               | synchronized |
| HashSet   | 16           | 0.75f        | 2倍          | HashMap<E,Object>   | 否               |              |
| HashMap   | 16           | 0.75f        | 2倍          | Map.Entry           | 否               |              |
| Hashtable | 11           | 0.75f        | 2倍+1        | Hashtable.Entry数组 | 是               | synchronized |

**3：数据同步层面**

ConcurrentHashMap 、HashTable、vector

**4：内存泄漏与回收**

hashmap、threadlocal

## 内存泄漏与JVM

**什么是Java中的内存泄露**

在Java中，内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点，首先，这些对象是可达的，即在有向图中，存在通路可以与其相连；其次，这些对象是无用的，即程序以后不会再使用这些对象。如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。

**1、静态集合类引起内存泄漏**

**2、当集合里面的对象属性被修改后，再调用remove()方法时不起作用**

**3、监听器**

**4、各种连接**

**5、内部类和外部模块的引用**

**6、单例模式**



## 设计模式整理

设计模式（面向对象）有七大原则，分别是：

　　**1.开放-封闭原则**

　　　　通俗：对扩展开发，对修改关闭

　　**2.单一职责原则**

　　　　通俗：一个类只做一件事

　　**3.依赖倒转原则**

　　　　通俗：类似IOC，采用接口编程

　　**4.迪米特法则（也称为最小知识原则）**

　　　　通俗：高内聚，低耦合

　　**5.接口隔离原则**

　　　　通俗：细节接口

　　**6.合成/聚合复用原则**

　　　　通俗：避免使用继承

　　**7.里氏代换原则**

　　　　通俗：子类不能去修改父类的功能 

**1. 根据目的来分**

根据模式是用来完成什么工作来划分，这种方式可分为创建型模式、结构型模式和行为型模式 3 种。

1. 创建型模式：用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。GoF 中提供了单例、原型、工厂方法、抽象工厂、建造者等 5 种创建型模式。
2. 结构型模式：用于描述如何将类或对象按某种布局组成更大的结构，GoF 中提供了代理、适配器、桥接、装饰、外观、享元、组合等 7 种结构型模式。
3. 行为型模式：用于描述类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，以及怎样分配职责。GoF 中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等 11 种行为型模式。



## 编译器原理

一般开发编译器的话。有两条路选，利用yacc(或者其变种)&lex(词法分析)-等工具自己生成语法模板。

**一个编译器的结构分为分析部分（编译器的前端）和综合部分（编译器的后端）。**


**编译器的前端：**把源程序分解成为多个组成要素，并在这些要素之上加上语法结构。然后，它使用这个结构来创建该源程序的一个中间表示。如检查出源程序没有按照正确的语法构成，或者语义上不一致，它就必须提供有用的信息，使得用户可以按此进行改正，在编译器的前端，还会收集有关源程序的信息，并把信息存放在一个成为符号表的数据结构中。

**编译器的后端：**根据中间表示和符号表中的信息来构造用户期待的目标程序。

![img](https://img-blog.csdn.net/20180909110157348?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pvd2VpY2Nj/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**词法分析（lexical analysis）：**词法分析也称作扫描，是编译器的第一个步骤，词法分析器读入组成源程序的字符流，并且将它们组织成为有意义的词素的序列，对于每一个词素，词法分析器产生如下形式的词法单元作为输出。实际上就是从字符流到单词流的过程。
   **词法单元：**<token-name，attribute-value>,在这个词法单元中，第一个分量是一个由语法分析步骤使用的抽象符号，而第二个分量指向符号表中关于这个词法单元的条目。符号表条目的信息会被语义分析和代码生成步骤使用。
**举个龙书里的例子吧：**position=initial+rate*60，在这个赋值语句中的字符可以组成如下词素，并映射成为如下词法单元，这些词法单元会被传递给语法分析阶段。
（1）position是一个词素，被映射成词法单元<id，1>，其中id是表示标识符的抽象符号，而1指向符号表中position对应的条目。一个标识符对应的符号表条目存放该标识符有关的信息，比如它的名字和类型。
（2）赋值符号=是一个词素，被映射成词法单元<=>。因为这个词法单元不需要属性值，所以我们可以忽略它的第二个分量。也可以使用assign这样的抽象符号作为此法单元的名字，
但是为了标记上的方便，我们选择使用词素本身作为抽象符号的名字。
（3）initial是一个词素，被映射成词法单元<id，2>，其中2指向initial对应的符号表条目。
（4）+是一个词素，被映射成词法单元<+>
（5）rate是一个词素，被映射成词法单元<id，3>，其中3指向rate对应的符号表条目。
（6）*是一个词素，被映射成词法单元<*>
（7）60是一个词素，被映射成词法单元<60>，实际上我们应该建立一个形如<number,4>的词法单元，其中4指向符号表中对应整数60的条目。
  单词的分类：标识符，常量，算符，界符（“；”，“，”），关键字

**语法分析：**也称作解析，语法分析器使用由词法分析器生成的各个词法单元的第一个分量来创建树形的中间表示。该中间表示给出了词法分析产生的词法单元流的语法结构。一个常用的表示方法是**语法树**，树中的每个内部结点表示一个运算，而该结点的子结点表示该运算的分量。

**语义分析：**语义分析器使用语法树和符号表中的信息来检查源程序是否和语言定义的语义一致。它同时也收集类型信息，并把这些信息存放在语法树或符号表中，以便在随后的中间代码生成过程中使用。语义分析的一个重要部分是**类型检查**，编译器检查每个运算符是否具有匹配的运算分量，比如数组下标必须是整数，若用一个浮点数来做下标，编译器就会报错。程序设计语言可能允许某些类型转换，这被称作***\*自动类型转换\****。


**中间代码生成：**在把一个源程序翻译成目标代码的过程中，一个编译器可能构造出一个或多个中间表示。这些中间表示可以有多种形式。其中语法树是一种中间表示形式。在源程序的语法分析和语义分析完成之后，很多编译器生成一个明确的低级的或类机器语言的中间表示，我们可以把这个表示看作是某个抽象机器的程序。该**中间表示**应该具有***\*两个重要的性质\****：
**易于生成，且能够被轻松地翻译为目标机器上的语言。**


**代码优化：**机器无关的代码优化步骤试图改进中间代码，以便生成更好的目标代码。**代码优化又分为中间代码优化和目标代码的优化。**


**代码生成：**代码生成器以源程序的中间表示形式作为输入，并把它映射到目标语言。如果目标语言是机器代码，那么必须为程序使用的每个变量选择寄存器或内存位置，然后，中间指令被翻译成为能够完成相同任务的机器指令序列。

**编译器的重要功能之一**是记录源程序中使用的变量的名字，并收集和每个名字的各种属性有关的信息。这些属性可以提供一个名字的存储分配、它的类型、作用于（即在程序的哪些地方可以使用这个名字的值）等信息。对于过程名字，这些信息还包括：它的参数数量和类型、每个参数的传递方法（比如传值或传引用）以及返回类型。

**符号表管理：**符号表数据结构为每个变量名字创建了一个记录条目。记录的字段就是名字的各个属性，这个数据结构应该允许编译器迅速查找到每个名字的记录，并向记录中快速存放和获取记录中的数据。
**趟（扫描）：**在一个特定的实现中，多个步骤的活动可以被组合成一趟。每趟读入一个输入文件并产生一个输出文件。**比如**：前端步骤中的全部步骤可以组合在一起成为一趟。代码优化可以作为一个可选的趟。然后可以有一个特定目标机生成代码的后端趟。

**程序设计语言基础**：
   **1.静态和动态：**直接看概念会感觉很绕，所以这里举了个Java的例子帮助理解，在Java类声明中static关键字的使用。
     这里比如声明：public static int x；使得x成为一个类变量，也就是说不管创建了多少个这个类的对象，只存在一个x的拷贝，最重要的是，编译器可以确定内存中的被用于存放整数x的位置，而如果在声明中忽略了“static”，那么这个类的每个对象都会有它自己的用于存放x的位置，编译器没有办法在运行程序之前预先确定所有这些位置
  **2.环境和状态：**
     环境是一个从名字到存储位置的映射。因为变量就是指内存位置（即C语言中的“左值”），可以换种说法，把环境定义为从名字到变量的映射。
     状态是一个内存位置到它们值得映射。（以C语言得术语来说，即状态把“左值”映射为它们得相应“右值”）
     **2.1静态绑定和动态绑定**
静态绑定：方法在程序编译期进行绑定
动态绑定：方法在程序运行时根据具体对象的类型进行绑定
大部分的名字到位置的绑定和位置到值的绑定都是动态绑定。
     **2.2声明和定义**
声明告诉我们事物的类型，而定义告诉我们它们的值。int i就是一个声明，i=1就是一个定义。
     **2.3名字、标识符和变量**
     **标识符**是一个字符串，用来指向一个实体，比如一个数据对象、过程、类、或者类型。所有标识符都是名字，但是所有的名字并不都是标识符，比如x.y就是一个受限名字而不是标识符。
**变量**指向存储中的某个特定的位置
     **2.4过程、函数和方法**
一个函数通常返回某个类型的值，而一个过程不返回任何值，而面向对象语言，比如Java,C++，通常使用术语“方法”。





实现编译器可大可小，而根据语言的不同，其复杂度也是不尽相同，甚至于说区别很大。而对于一个普通的编译器来说，按照编译原理来说，你需要考虑的是以下几大块。

\1. 词法分析器 
    将输入的字符流转换为特定的单词。这一步是识别组合字符的过程，识别出数字，标识符，关键字等过程就在于此。若我们这里设计的编译器不包含预处理器，那么，在这里还需要做一些预处理的过程，如识别出注释，并将其忽略掉。这一步的输入是字符，输出是单词。

\2. 语法分析器
    将输入的单词流转换为特定的语句。这里面需要做的就是组合单词，并按照特定的语法规则去匹配出合法的语句。如 if （ bool-expression ）{ statement } 就是简单的if 语句，而所需要的就有关键字 if ，符号 ( ，表达式，符号 ）， 符号 ｛ ，  合法的语句， 符号 ｝。而这里的表达式与合法语句则又有合法的单词流组成。而我们把这一步处理完毕后，我们流下我们所需要关注的核心内容。如if 语句，我们传递下去后，我们就不需要符号 （ ） ｛ ｝等了。而表示这样的核心内容则是抽象语法树（Abstract Syntax Tree ，简称AST）。

\3. 语义分析
   在进行下一步前，我们往往会对AST进行分析。如类型匹配，这样的语意是否正确等。如简单的int i = "hello"; 那么我们在遍历AST的时候，则会识别出来类型问题。而在这里我们往往需要一个符号表来记录变量以及对应的类型，然后分析AST的时候来进行查询与处理等。这一步的输入是AST，输出依然是AST。

\4. 代码生成
   这一步处于来编译器前端与后端的交界处。一般来说，我们会设计一个抽象于机器平台的中间语言( Intermediate Representation，简称IR ) 以便于进行后续机器无关的优化（如死代码消除，函数内联优化，for循环展开等）以及生成多机器平台的底层代码。在这一方面，往往有两个选择，一个是基于栈的IR，一个是基于寄存器的IR。前者易于编程与操作，而后者则性能更好。一般来说，很多编译型语言的IR都是基于寄存器的，如LLVM IR，微软编译器的中间语言等，而一些虚拟机平台的则是基于栈的。然而凡是也有例外，如在鲸书曾写道了我司编译器的WCode，则是基于栈的，而里面也提到了很多编译器有不止一个中间语言，这一个就不细谈了。对于鲸书，虽然有一些内容信息已经过时了，但是依然是神书。而这一步，就如今来说，我们往往也不自己来设计IR了，因为若走上这一条路，我们就会投入到无边无尽的后端工作中。那么，感谢伟大的LLVM，我们可以让我们的AST生成LLVM IR，避免掉繁琐的后端工作。我们所需要做的尽只是在AST中添加一个codeGen方法，然后利用LLVM IR API来生成LLVM IR。这一步的输入是AST，输出为IR。

5.代码优化
   这一步则是来让代码更加的高效。一般来说，我们分为了机器无关优化与机器相关优化。机器无关的优化则是前面提到的一些内容，而若选择LLVM，我们可以轻易利用LLVM的各种优化pass来帮我们做到这一点。而机器相关优化，则是与硬件平台相关，我们往往需要利用一些硬件平台的特性来帮助优化。这一步输入是IR, 输出依然是IR。而若编译器有多套的IR，那么可能输入的IR与输出的IR是不一样格式的IR，但是如LLVM这样的则是同一套IR。

\6. 目标代码生成
  这一步则是生成目标平台代码。如若是编译型语言，则往往是产生.o文件，到这一步的时候，其实编译器的真正意义工作已经结束了。

7＊. Driver驱动器
   在很多编译器中，我们不仅是到达.o文件，我们还可以调用链接器，汇编器然后生成可执行文件，而这样的工作其实是在一个driver中完成。而driver不仅完成工具链的调用工作，往往也会处理编译选项。如gcc -std=c++11 a.C 那么-std=c++11这一个选项的识别则是在driver中完成。

8＊. 错误信息机制
   对于一个编译器来说，其还有一项则是错误的提示。而这一个耗时耗力，也是往往是编译器开发人员不太在意的，大家都想去做高大上的实现，体力活都不想做。这一步却往往是与用户最直接相关的，所以如何设计一个好的错误信息机制也是很重要的一点。

9 ... （如何支持多个源文件的编译？等）



## 并发有多少



**怎么根据并发计算网站需要多大带宽？**

例子，网页基本在60K左右，一般人的等待忍耐是3到5秒

按照1秒计算则每个网页占用的带宽是60k/s

如果1000人同时访问的话：1000x60/1024=58.6M

按照3秒计算 则每个网页占用的带宽是 20K/S

如果1000人访问的话:1000x20/1024=19M

如果是5秒计算的话则每个网页占用的带宽是12K/S

如果1000人访问的话：1000x12/1024=11M

这个只是根据理论上的一个大概估算，实际情况会稍微高点。



**PV=page view**

是指页面被浏览的次数，比如你打开一网页，那么这个网站的pv就算加了一次；

 **TPS=transactions per second**
 是每秒内的事务数，比如执行了dml操作，那么相应的tps会增加；

 **QPS=queries per second**
 是指每秒内查询次数，比如执行了select操作，相应的qps会增加。
 QPS = req/sec = 请求数/秒



- QPS = req/sec = 请求数/秒

- QPS计算PV和机器的方式

  - QPS统计方式 [一般使用 http_load 进行统计]
  - QPS = 总请求数 / ( 进程总数 * 请求时间 )
  - QPS: 单个进程每秒请求服务器的成功次数

- 单台服务器每天PV计算

  公式1：每天总PV = QPS * 3600 * 6

  公式2：每天总PV = QPS * 3600 * 8

- 服务器计算

  服务器数量 = ceil( 每天总PV / 单台服务器每天总PV )

- 峰值QPS和机器计算公式

  **原理：**每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间

  **公式：**( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS)

  **机器：**峰值时间每秒QPS / 单台机器的QPS = 需要的机器

  - 问：每天300w PV 的在单台机器上，这台机器需要多少QPS？

    ( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)

  - 如果一台机器的QPS是58，需要几台机器来支持？

    139 / 58 = 3

- **举例说明：**

  上班签到系统，早上8点上班，7点半到8点的30分钟的时间里用户会登录签到系统进行签到。公司员工为1000人，平均每个员上登录签到系统的时长为5分钟。可以用下面的方法计算。
  QPS = 1000/(30 * 60) 事务/秒
  平均响应时间为 = 5 * 60 秒
  并发数= QPS * 平均响应时间 = 1000/(30 * 60) * (5 * 60)=166.7





## 自我介绍整理

个人方面：已婚，工作稳定，不打游戏，活到老学到老，很强的快速学习能力，崇尚科学

学校方面：就读于中国地质大学，研三，计算机专业，NLP，python，多个项目，k8s环境、毕设

工作方面：6年Java，互联网，springmvc、springboot、rabbitmq、kafka、redis、mysql、docker



## **为什么考研**

1. 系统的深造一下自己。自己也是比较爱学习，喜欢研究技术，读了挺多技术类书籍，也有不明白的地方，尤其是机器学习和深度学习，概念挺多，通过读研的方式系统的深造一下自己。
2. 活到老学到老。相信知识就是力量，自己处于持续学习，因为知道技术持续变革，不学习很快就被淘汰。
3. 提升自己的竞争力。预感到竞争越来越激烈，提升自己的竞争力。



## 目前offer有几个

京东物流，小米游戏支付，还有小的上市公司给期权，3年拿完。

小的上市公司流程很快，发了offer，大的公司都再谈，我再想想。没有让他们发offer，发了不去，感觉失信于人。

更看重银行，做金融，国家对金融风控的严监管，银行前景很好，稳定。



现在聊的薪资可以保密吗？感觉说了不太好，我可以说说我在寺库的薪资，过了2年多了，可能人家薪酬结构也变了，对人家没什么影响。18 * 15，有季度奖金，年包大概是30-35之间吧。



兴业数字金融服务（上海）股份有限公司（简称“兴业数金”）成立于2015年12月，

兴业数金是家金融信息服务公司,是未来[银银平台](https://baike.baidu.com/item/银银平台/2968719)逐步实现分拆,完成兴业银行大金控梦想的重要子公司，兴业数金公司经营范围：金融数据处理，经济信息咨询服务，应用软件开发和运营服务，系统集成服务，股权投资，股权投资管理，创业投资，资产管理， 投资管理，投资咨询。

2019年，兴业银行推进科技体制机制改革 总行科技研发力量打包注入兴业数金 。

[兴业银行](https://baike.baidu.com/item/兴业银行/635248)（601166）宣布该行“银银平台”理财门户全新升级，并推出互联网理财品牌——“钱大掌柜”，这是继2007年该行在国内率先推出银银合作品牌“银银平台”，全面推进支付结算、信息科技、资产负债管理等各项银银合作业务之后，针对财富管理业务的又一重要布局。 



数字金融服务，银行来做。

***数字金融*** 是指通过互联网及信息技术手段与传统金融服务业态相结合的新一代金融服务。

未来发展方向：智能、便捷、风控、安全、多元金融

**FGBC协同联动、融合赋能**

立足F端领先优势，兴业银行进一步将其复制嫁接到政府端（即G端）、企业端（即B端），不断推进GBC端场景拓展和生态互联，通过互联互通，让金融服务触达C端的“千家万户”，形成FGBC协同联动、融合赋能的开放生态。

G端，加深互联合作，增强与政府机构和公共事业单位互联和数据共享，积极开展社保代发、住房公积金、海关税费等多个领域的服务嵌入。

B端，持续扩大领先优势，打通B2B2C价值链。

C端，推进“织网工程”建设。兴业银行全力打造移动生活平台“好兴动”APP，通过“织网”工程与餐饮、娱乐等商户深度合作，全面融入用户吃、喝、玩、购、乐等生活消费场景，并探索基于各类生活消费场景的发卡、特惠、收单、代发、分期等金融服务，构建多方共赢的互联网生态闭环。目前合作商户近8万家，注册用户数突破970万。



**如果你手上确实没有offer，那就说没有。**

你可以说：“刚刚在找工作，您是我面试的第一家公司。”你也可以这样说：“目前有2家公司在沟通，还没有发书面offer。”

如果手上有offer，可以直接告知面试官。但是要考虑的是，面试官可能会问你这些问题，你要做好表达。

**1、你手上有offer，为什么还要来我们公司面试呢？**

直男型回答：“因为我想多比较比较，看看哪个更合适。”

虽然这是绝大多数求职者内心最真实的想法，但是面试官会觉得自己公司在你眼里原来也是备胎。

**2、是哪家公司给你offer的？他们给你offer多少薪资？**

如果面试官现场问你这个问题，说明他对你还是很有认可度的。

这时候，建议大家不要说具体公司的名字和具体薪资。

因为如果是同行业的企业，很多圈内的面试官消息是互通的。所以，你可以这样回答面试官：

“有一家offer是做房地产的公司，另一家offer是做在线教育的互联网企业。”

**关于offer的具体薪资千万不要主动说。**

**提醒大家几点：**

1、不管你有没有offer，都不要欺骗面试官，还是真诚些好。

2、如果没有技术傍身，没有好的职场背景，不要裸辞，因为offer永远留给有能力有准备的人。

3、找工作是双向选择，没必要为了迎合面试官而放烟雾弹。最后，祝愿大家都能在职场中找到自己满意的工作。







## 描述一个项目

项目背景：主营业务是线上拍卖，拍卖会线上拍卖，和线下同步进行。委托代拍和线上竞拍。

架构设计：git、maven、springboot、dubbo、zookeeper、docker、kubernets、mysql、redis、Jenkins

技术难点：pc端，ios端，安卓端同时进行，基于http的长连接，兼容http1.0，观察者模式

微服务模块：会员、商品、订单、支付、营销

**分库分表方案**

按模块分库、水平分表（mycat）

## 优点和缺点

优点：比较好的适应能力、融入能力、快速学习能力等等。

缺点：学得快，忘得也快。

缺点：第一个是选择，总会比较多个方案，选择最优的一个，浪费了时间；第二个，比较轴，意见分歧的时候，总觉得自己是对的，不愿承认自己的错误，各种途径找答案，为什么是自己错了，喜欢刨根问题。太重情义了，朋友借钱。



## 未来规划

成为一名出色的架构师

一、卓越的程序员：每个好架构师都是一位出色的程序员

二、抽象思维：驾驭概念的技能是最高潜力

三、技术前瞻性：站在技术的山顶向前眺望

四、透过问题看本质：解决问题和绕开问题

五、跨域知识：要成为百科全书式的智者



## 要问面试官的问题

1：部门整体业务

2：自己可能的工作内容

3：未来晋升空间